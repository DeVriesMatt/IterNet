{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Final_Emer_Iteration_3_cropsize_128_epochs_200\n",
      "WARNING:tensorflow:From /home/li/anaconda3/envs/univ/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/li/anaconda3/envs/univ/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/li/anaconda3/envs/univ/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li/anaconda3/envs/univ/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "62/62 [==============================] - 20s 327ms/step - loss: 2.7983 - out11_loss: 0.3567 - out12_loss: 0.3852 - out13_loss: 1.0079 - final_out_loss: 1.0485 - final_out_acc: 0.8703\n",
      "\n",
      "Epoch 00001: final_out_loss improved from inf to 0.99982, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 2/200\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 1.2252 - out11_loss: 0.2710 - out12_loss: 0.2735 - out13_loss: 0.3270 - final_out_loss: 0.3537 - final_out_acc: 0.8582\n",
      "\n",
      "Epoch 00002: final_out_loss improved from 0.99982 to 0.34628, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 3/200\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 1.0541 - out11_loss: 0.2625 - out12_loss: 0.2627 - out13_loss: 0.2648 - final_out_loss: 0.2641 - final_out_acc: 0.8575\n",
      "\n",
      "Epoch 00003: final_out_loss improved from 0.34628 to 0.26813, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 4/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 1.3158 - out11_loss: 0.3277 - out12_loss: 0.3285 - out13_loss: 0.3301 - final_out_loss: 0.3296 - final_out_acc: 0.8190\n",
      "\n",
      "Epoch 00004: final_out_loss did not improve from 0.26813\n",
      "Epoch 5/200\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 1.1262 - out11_loss: 0.2807 - out12_loss: 0.2810 - out13_loss: 0.2825 - final_out_loss: 0.2820 - final_out_acc: 0.8462\n",
      "\n",
      "Epoch 00005: final_out_loss did not improve from 0.26813\n",
      "Epoch 6/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 1.1059 - out11_loss: 0.2761 - out12_loss: 0.2751 - out13_loss: 0.2769 - final_out_loss: 0.2777 - final_out_acc: 0.8432\n",
      "\n",
      "Epoch 00006: final_out_loss did not improve from 0.26813\n",
      "Epoch 7/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 1.0174 - out11_loss: 0.2522 - out12_loss: 0.2555 - out13_loss: 0.2555 - final_out_loss: 0.2543 - final_out_acc: 0.8584\n",
      "\n",
      "Epoch 00007: final_out_loss improved from 0.26813 to 0.26521, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 8/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 1.0335 - out11_loss: 0.2598 - out12_loss: 0.2582 - out13_loss: 0.2580 - final_out_loss: 0.2575 - final_out_acc: 0.8515\n",
      "\n",
      "Epoch 00008: final_out_loss improved from 0.26521 to 0.25792, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 9/200\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 1.0307 - out11_loss: 0.2682 - out12_loss: 0.2589 - out13_loss: 0.2520 - final_out_loss: 0.2516 - final_out_acc: 0.8510\n",
      "\n",
      "Epoch 00009: final_out_loss improved from 0.25792 to 0.25237, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 10/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.9313 - out11_loss: 0.2540 - out12_loss: 0.2385 - out13_loss: 0.2206 - final_out_loss: 0.2181 - final_out_acc: 0.8612\n",
      "\n",
      "Epoch 00010: final_out_loss improved from 0.25237 to 0.21985, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 11/200\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 0.8233 - out11_loss: 0.2459 - out12_loss: 0.2085 - out13_loss: 0.1852 - final_out_loss: 0.1837 - final_out_acc: 0.8706\n",
      "\n",
      "Epoch 00011: final_out_loss improved from 0.21985 to 0.18863, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 12/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.6493 - out11_loss: 0.2078 - out12_loss: 0.1524 - out13_loss: 0.1451 - final_out_loss: 0.1441 - final_out_acc: 0.8854\n",
      "\n",
      "Epoch 00012: final_out_loss improved from 0.18863 to 0.14399, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 13/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.7137 - out11_loss: 0.2229 - out12_loss: 0.1673 - out13_loss: 0.1625 - final_out_loss: 0.1609 - final_out_acc: 0.8592\n",
      "\n",
      "Epoch 00013: final_out_loss did not improve from 0.14399\n",
      "Epoch 14/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.6475 - out11_loss: 0.1862 - out12_loss: 0.1547 - out13_loss: 0.1541 - final_out_loss: 0.1526 - final_out_acc: 0.8760\n",
      "\n",
      "Epoch 00014: final_out_loss did not improve from 0.14399\n",
      "Epoch 15/200\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 0.6655 - out11_loss: 0.1776 - out12_loss: 0.1632 - out13_loss: 0.1632 - final_out_loss: 0.1615 - final_out_acc: 0.8602\n",
      "\n",
      "Epoch 00015: final_out_loss did not improve from 0.14399\n",
      "Epoch 16/200\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 0.5336 - out11_loss: 0.1425 - out12_loss: 0.1304 - out13_loss: 0.1310 - final_out_loss: 0.1297 - final_out_acc: 0.8820\n",
      "\n",
      "Epoch 00016: final_out_loss improved from 0.14399 to 0.12862, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 17/200\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 0.5666 - out11_loss: 0.1490 - out12_loss: 0.1396 - out13_loss: 0.1396 - final_out_loss: 0.1384 - final_out_acc: 0.8735\n",
      "\n",
      "Epoch 00017: final_out_loss did not improve from 0.12862\n",
      "Epoch 18/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.5414 - out11_loss: 0.1418 - out12_loss: 0.1336 - out13_loss: 0.1336 - final_out_loss: 0.1325 - final_out_acc: 0.8741\n",
      "\n",
      "Epoch 00018: final_out_loss did not improve from 0.12862\n",
      "Epoch 19/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.4739 - out11_loss: 0.1233 - out12_loss: 0.1169 - out13_loss: 0.1177 - final_out_loss: 0.1159 - final_out_acc: 0.8909\n",
      "\n",
      "Epoch 00019: final_out_loss improved from 0.12862 to 0.11450, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 20/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.4545 - out11_loss: 0.1194 - out12_loss: 0.1113 - out13_loss: 0.1123 - final_out_loss: 0.1115 - final_out_acc: 0.9016\n",
      "\n",
      "Epoch 00020: final_out_loss improved from 0.11450 to 0.11330, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 21/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.4417 - out11_loss: 0.1167 - out12_loss: 0.1083 - out13_loss: 0.1086 - final_out_loss: 0.1081 - final_out_acc: 0.8960\n",
      "\n",
      "Epoch 00021: final_out_loss improved from 0.11330 to 0.10749, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 22/200\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 0.3839 - out11_loss: 0.1007 - out12_loss: 0.0942 - out13_loss: 0.0947 - final_out_loss: 0.0942 - final_out_acc: 0.9137\n",
      "\n",
      "Epoch 00022: final_out_loss improved from 0.10749 to 0.09418, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 23/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.4741 - out11_loss: 0.1252 - out12_loss: 0.1165 - out13_loss: 0.1168 - final_out_loss: 0.1157 - final_out_acc: 0.8838\n",
      "\n",
      "Epoch 00023: final_out_loss did not improve from 0.09418\n",
      "Epoch 24/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.4588 - out11_loss: 0.1207 - out12_loss: 0.1127 - out13_loss: 0.1130 - final_out_loss: 0.1125 - final_out_acc: 0.8818\n",
      "\n",
      "Epoch 00024: final_out_loss did not improve from 0.09418\n",
      "Epoch 25/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.4421 - out11_loss: 0.1157 - out12_loss: 0.1087 - out13_loss: 0.1091 - final_out_loss: 0.1086 - final_out_acc: 0.8901\n",
      "\n",
      "Epoch 00025: final_out_loss did not improve from 0.09418\n",
      "Epoch 26/200\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 0.5045 - out11_loss: 0.1327 - out12_loss: 0.1238 - out13_loss: 0.1243 - final_out_loss: 0.1237 - final_out_acc: 0.8760\n",
      "\n",
      "Epoch 00026: final_out_loss did not improve from 0.09418\n",
      "Epoch 27/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.5077 - out11_loss: 0.1331 - out12_loss: 0.1249 - out13_loss: 0.1251 - final_out_loss: 0.1245 - final_out_acc: 0.8631\n",
      "\n",
      "Epoch 00027: final_out_loss did not improve from 0.09418\n",
      "Epoch 28/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.4603 - out11_loss: 0.1194 - out12_loss: 0.1135 - out13_loss: 0.1140 - final_out_loss: 0.1134 - final_out_acc: 0.8869\n",
      "\n",
      "Epoch 00028: final_out_loss did not improve from 0.09418\n",
      "Epoch 29/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.4889 - out11_loss: 0.1260 - out12_loss: 0.1205 - out13_loss: 0.1216 - final_out_loss: 0.1208 - final_out_acc: 0.8752\n",
      "\n",
      "Epoch 00029: final_out_loss did not improve from 0.09418\n",
      "Epoch 30/200\n",
      "62/62 [==============================] - 13s 218ms/step - loss: 0.4798 - out11_loss: 0.1249 - out12_loss: 0.1184 - out13_loss: 0.1185 - final_out_loss: 0.1180 - final_out_acc: 0.8794\n",
      "\n",
      "Epoch 00030: final_out_loss did not improve from 0.09418\n",
      "Epoch 31/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.4599 - out11_loss: 0.1196 - out12_loss: 0.1134 - out13_loss: 0.1137 - final_out_loss: 0.1133 - final_out_acc: 0.8867\n",
      "\n",
      "Epoch 00031: final_out_loss did not improve from 0.09418\n",
      "Epoch 32/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.4446 - out11_loss: 0.1160 - out12_loss: 0.1096 - out13_loss: 0.1097 - final_out_loss: 0.1092 - final_out_acc: 0.8799\n",
      "\n",
      "Epoch 00032: final_out_loss did not improve from 0.09418\n",
      "Epoch 33/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.4205 - out11_loss: 0.1089 - out12_loss: 0.1037 - out13_loss: 0.1042 - final_out_loss: 0.1036 - final_out_acc: 0.8893\n",
      "\n",
      "Epoch 00033: final_out_loss did not improve from 0.09418\n",
      "Epoch 34/200\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 0.4383 - out11_loss: 0.1143 - out12_loss: 0.1079 - out13_loss: 0.1082 - final_out_loss: 0.1079 - final_out_acc: 0.8893\n",
      "\n",
      "Epoch 00034: final_out_loss did not improve from 0.09418\n",
      "Epoch 35/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.4793 - out11_loss: 0.1251 - out12_loss: 0.1181 - out13_loss: 0.1183 - final_out_loss: 0.1178 - final_out_acc: 0.8746\n",
      "\n",
      "Epoch 00035: final_out_loss did not improve from 0.09418\n",
      "Epoch 36/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.4360 - out11_loss: 0.1133 - out12_loss: 0.1076 - out13_loss: 0.1077 - final_out_loss: 0.1074 - final_out_acc: 0.8842\n",
      "\n",
      "Epoch 00036: final_out_loss did not improve from 0.09418\n",
      "Epoch 37/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.4586 - out11_loss: 0.1189 - out12_loss: 0.1133 - out13_loss: 0.1134 - final_out_loss: 0.1129 - final_out_acc: 0.8782\n",
      "\n",
      "Epoch 00037: final_out_loss did not improve from 0.09418\n",
      "Epoch 38/200\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 0.4178 - out11_loss: 0.1084 - out12_loss: 0.1033 - out13_loss: 0.1033 - final_out_loss: 0.1028 - final_out_acc: 0.8897\n",
      "\n",
      "Epoch 00038: final_out_loss did not improve from 0.09418\n",
      "Epoch 39/200\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 0.4406 - out11_loss: 0.1146 - out12_loss: 0.1088 - out13_loss: 0.1088 - final_out_loss: 0.1084 - final_out_acc: 0.8818\n",
      "\n",
      "Epoch 00039: final_out_loss did not improve from 0.09418\n",
      "Epoch 40/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.4278 - out11_loss: 0.1108 - out12_loss: 0.1057 - out13_loss: 0.1059 - final_out_loss: 0.1054 - final_out_acc: 0.8886\n",
      "\n",
      "Epoch 00040: final_out_loss did not improve from 0.09418\n",
      "Epoch 41/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.4287 - out11_loss: 0.1111 - out12_loss: 0.1059 - out13_loss: 0.1060 - final_out_loss: 0.1056 - final_out_acc: 0.8786\n",
      "\n",
      "Epoch 00041: final_out_loss did not improve from 0.09418\n",
      "Epoch 42/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.4334 - out11_loss: 0.1124 - out12_loss: 0.1071 - out13_loss: 0.1071 - final_out_loss: 0.1067 - final_out_acc: 0.8789\n",
      "\n",
      "Epoch 00042: final_out_loss did not improve from 0.09418\n",
      "Epoch 43/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.4302 - out11_loss: 0.1114 - out12_loss: 0.1063 - out13_loss: 0.1064 - final_out_loss: 0.1061 - final_out_acc: 0.8838\n",
      "\n",
      "Epoch 00043: final_out_loss did not improve from 0.09418\n",
      "Epoch 44/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.4608 - out11_loss: 0.1189 - out12_loss: 0.1140 - out13_loss: 0.1141 - final_out_loss: 0.1138 - final_out_acc: 0.8721\n",
      "\n",
      "Epoch 00044: final_out_loss did not improve from 0.09418\n",
      "Epoch 45/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.4176 - out11_loss: 0.1079 - out12_loss: 0.1032 - out13_loss: 0.1034 - final_out_loss: 0.1030 - final_out_acc: 0.8932\n",
      "\n",
      "Epoch 00045: final_out_loss did not improve from 0.09418\n",
      "Epoch 46/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.4534 - out11_loss: 0.1172 - out12_loss: 0.1121 - out13_loss: 0.1122 - final_out_loss: 0.1119 - final_out_acc: 0.8766\n",
      "\n",
      "Epoch 00046: final_out_loss did not improve from 0.09418\n",
      "Epoch 47/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.4395 - out11_loss: 0.1130 - out12_loss: 0.1086 - out13_loss: 0.1092 - final_out_loss: 0.1088 - final_out_acc: 0.8799\n",
      "\n",
      "Epoch 00047: final_out_loss did not improve from 0.09418\n",
      "Epoch 48/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.4637 - out11_loss: 0.1200 - out12_loss: 0.1146 - out13_loss: 0.1147 - final_out_loss: 0.1144 - final_out_acc: 0.8724\n",
      "\n",
      "Epoch 00048: final_out_loss did not improve from 0.09418\n",
      "Epoch 49/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.4474 - out11_loss: 0.1148 - out12_loss: 0.1104 - out13_loss: 0.1112 - final_out_loss: 0.1109 - final_out_acc: 0.8764\n",
      "\n",
      "Epoch 00049: final_out_loss did not improve from 0.09418\n",
      "Epoch 50/200\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 0.4543 - out11_loss: 0.1171 - out12_loss: 0.1125 - out13_loss: 0.1125 - final_out_loss: 0.1122 - final_out_acc: 0.8753\n",
      "\n",
      "Epoch 00050: final_out_loss did not improve from 0.09418\n",
      "Epoch 51/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.4132 - out11_loss: 0.1069 - out12_loss: 0.1023 - out13_loss: 0.1022 - final_out_loss: 0.1019 - final_out_acc: 0.8814\n",
      "\n",
      "Epoch 00051: final_out_loss did not improve from 0.09418\n",
      "Epoch 52/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.3978 - out11_loss: 0.1022 - out12_loss: 0.0984 - out13_loss: 0.0987 - final_out_loss: 0.0984 - final_out_acc: 0.8956\n",
      "\n",
      "Epoch 00052: final_out_loss did not improve from 0.09418\n",
      "Epoch 53/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.3790 - out11_loss: 0.0976 - out12_loss: 0.0938 - out13_loss: 0.0939 - final_out_loss: 0.0937 - final_out_acc: 0.9000\n",
      "\n",
      "Epoch 00053: final_out_loss improved from 0.09418 to 0.09267, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 54/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.3588 - out11_loss: 0.0919 - out12_loss: 0.0887 - out13_loss: 0.0892 - final_out_loss: 0.0890 - final_out_acc: 0.9060\n",
      "\n",
      "Epoch 00054: final_out_loss improved from 0.09267 to 0.08965, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 55/200\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 0.4260 - out11_loss: 0.1104 - out12_loss: 0.1053 - out13_loss: 0.1052 - final_out_loss: 0.1050 - final_out_acc: 0.8824\n",
      "\n",
      "Epoch 00055: final_out_loss did not improve from 0.08965\n",
      "Epoch 56/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.3678 - out11_loss: 0.0948 - out12_loss: 0.0911 - out13_loss: 0.0911 - final_out_loss: 0.0908 - final_out_acc: 0.8985\n",
      "\n",
      "Epoch 00056: final_out_loss did not improve from 0.08965\n",
      "Epoch 57/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.3805 - out11_loss: 0.0979 - out12_loss: 0.0943 - out13_loss: 0.0943 - final_out_loss: 0.0940 - final_out_acc: 0.8970\n",
      "\n",
      "Epoch 00057: final_out_loss did not improve from 0.08965\n",
      "Epoch 58/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3633 - out11_loss: 0.0933 - out12_loss: 0.0901 - out13_loss: 0.0901 - final_out_loss: 0.0898 - final_out_acc: 0.8993\n",
      "\n",
      "Epoch 00058: final_out_loss did not improve from 0.08965\n",
      "Epoch 59/200\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.4402 - out11_loss: 0.1134 - out12_loss: 0.1090 - out13_loss: 0.1090 - final_out_loss: 0.1087 - final_out_acc: 0.8772\n",
      "\n",
      "Epoch 00059: final_out_loss did not improve from 0.08965\n",
      "Epoch 60/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3838 - out11_loss: 0.0989 - out12_loss: 0.0951 - out13_loss: 0.0950 - final_out_loss: 0.0948 - final_out_acc: 0.8919\n",
      "\n",
      "Epoch 00060: final_out_loss did not improve from 0.08965\n",
      "Epoch 61/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.4254 - out11_loss: 0.1094 - out12_loss: 0.1054 - out13_loss: 0.1054 - final_out_loss: 0.1051 - final_out_acc: 0.8833\n",
      "\n",
      "Epoch 00061: final_out_loss did not improve from 0.08965\n",
      "Epoch 62/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.3976 - out11_loss: 0.1019 - out12_loss: 0.0985 - out13_loss: 0.0987 - final_out_loss: 0.0985 - final_out_acc: 0.8930\n",
      "\n",
      "Epoch 00062: final_out_loss did not improve from 0.08965\n",
      "Epoch 63/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.4060 - out11_loss: 0.1043 - out12_loss: 0.1005 - out13_loss: 0.1006 - final_out_loss: 0.1006 - final_out_acc: 0.8874\n",
      "\n",
      "Epoch 00063: final_out_loss did not improve from 0.08965\n",
      "Epoch 64/200\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 0.3974 - out11_loss: 0.1020 - out12_loss: 0.0983 - out13_loss: 0.0986 - final_out_loss: 0.0985 - final_out_acc: 0.8859\n",
      "\n",
      "Epoch 00064: final_out_loss did not improve from 0.08965\n",
      "Epoch 65/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.3539 - out11_loss: 0.0910 - out12_loss: 0.0877 - out13_loss: 0.0877 - final_out_loss: 0.0875 - final_out_acc: 0.8957\n",
      "\n",
      "Epoch 00065: final_out_loss improved from 0.08965 to 0.08586, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 66/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.4086 - out11_loss: 0.1050 - out12_loss: 0.1012 - out13_loss: 0.1014 - final_out_loss: 0.1011 - final_out_acc: 0.8856\n",
      "\n",
      "Epoch 00066: final_out_loss did not improve from 0.08586\n",
      "Epoch 67/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.4042 - out11_loss: 0.1040 - out12_loss: 0.1002 - out13_loss: 0.1001 - final_out_loss: 0.0999 - final_out_acc: 0.8912\n",
      "\n",
      "Epoch 00067: final_out_loss did not improve from 0.08586\n",
      "Epoch 68/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.3916 - out11_loss: 0.1009 - out12_loss: 0.0970 - out13_loss: 0.0969 - final_out_loss: 0.0967 - final_out_acc: 0.8908\n",
      "\n",
      "Epoch 00068: final_out_loss did not improve from 0.08586\n",
      "Epoch 69/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.4317 - out11_loss: 0.1112 - out12_loss: 0.1070 - out13_loss: 0.1069 - final_out_loss: 0.1067 - final_out_acc: 0.8756\n",
      "\n",
      "Epoch 00069: final_out_loss did not improve from 0.08586\n",
      "Epoch 70/200\n",
      "62/62 [==============================] - 14s 223ms/step - loss: 0.4449 - out11_loss: 0.1145 - out12_loss: 0.1104 - out13_loss: 0.1102 - final_out_loss: 0.1099 - final_out_acc: 0.8700\n",
      "\n",
      "Epoch 00070: final_out_loss did not improve from 0.08586\n",
      "Epoch 71/200\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 0.3966 - out11_loss: 0.1020 - out12_loss: 0.0983 - out13_loss: 0.0982 - final_out_loss: 0.0980 - final_out_acc: 0.8873\n",
      "\n",
      "Epoch 00071: final_out_loss did not improve from 0.08586\n",
      "Epoch 72/200\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 0.3819 - out11_loss: 0.0983 - out12_loss: 0.0945 - out13_loss: 0.0947 - final_out_loss: 0.0945 - final_out_acc: 0.8943\n",
      "\n",
      "Epoch 00072: final_out_loss did not improve from 0.08586\n",
      "Epoch 73/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.4286 - out11_loss: 0.1104 - out12_loss: 0.1063 - out13_loss: 0.1061 - final_out_loss: 0.1058 - final_out_acc: 0.8836\n",
      "\n",
      "Epoch 00073: final_out_loss did not improve from 0.08586\n",
      "Epoch 74/200\n",
      "62/62 [==============================] - 13s 218ms/step - loss: 0.4212 - out11_loss: 0.1081 - out12_loss: 0.1043 - out13_loss: 0.1045 - final_out_loss: 0.1043 - final_out_acc: 0.8857\n",
      "\n",
      "Epoch 00074: final_out_loss did not improve from 0.08586\n",
      "Epoch 75/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.3966 - out11_loss: 0.1022 - out12_loss: 0.0983 - out13_loss: 0.0981 - final_out_loss: 0.0980 - final_out_acc: 0.8874\n",
      "\n",
      "Epoch 00075: final_out_loss did not improve from 0.08586\n",
      "Epoch 76/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.3813 - out11_loss: 0.0982 - out12_loss: 0.0946 - out13_loss: 0.0944 - final_out_loss: 0.0941 - final_out_acc: 0.8887\n",
      "\n",
      "Epoch 00076: final_out_loss did not improve from 0.08586\n",
      "Epoch 77/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.3973 - out11_loss: 0.1022 - out12_loss: 0.0985 - out13_loss: 0.0984 - final_out_loss: 0.0982 - final_out_acc: 0.8865\n",
      "\n",
      "Epoch 00077: final_out_loss did not improve from 0.08586\n",
      "Epoch 78/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.4025 - out11_loss: 0.1037 - out12_loss: 0.0998 - out13_loss: 0.0996 - final_out_loss: 0.0994 - final_out_acc: 0.8839\n",
      "\n",
      "Epoch 00078: final_out_loss did not improve from 0.08586\n",
      "Epoch 79/200\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 0.4633 - out11_loss: 0.1189 - out12_loss: 0.1150 - out13_loss: 0.1148 - final_out_loss: 0.1146 - final_out_acc: 0.8647\n",
      "\n",
      "Epoch 00079: final_out_loss did not improve from 0.08586\n",
      "Epoch 80/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.4066 - out11_loss: 0.1042 - out12_loss: 0.1007 - out13_loss: 0.1009 - final_out_loss: 0.1008 - final_out_acc: 0.8888\n",
      "\n",
      "Epoch 00080: final_out_loss did not improve from 0.08586\n",
      "Epoch 81/200\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.3948 - out11_loss: 0.1008 - out12_loss: 0.0981 - out13_loss: 0.0980 - final_out_loss: 0.0978 - final_out_acc: 0.8875\n",
      "\n",
      "Epoch 00081: final_out_loss did not improve from 0.08586\n",
      "Epoch 82/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3875 - out11_loss: 0.0992 - out12_loss: 0.0960 - out13_loss: 0.0962 - final_out_loss: 0.0961 - final_out_acc: 0.8913\n",
      "\n",
      "Epoch 00082: final_out_loss did not improve from 0.08586\n",
      "Epoch 83/200\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 0.4154 - out11_loss: 0.1066 - out12_loss: 0.1030 - out13_loss: 0.1029 - final_out_loss: 0.1028 - final_out_acc: 0.8791\n",
      "\n",
      "Epoch 00083: final_out_loss did not improve from 0.08586\n",
      "Epoch 84/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.3962 - out11_loss: 0.1015 - out12_loss: 0.0983 - out13_loss: 0.0983 - final_out_loss: 0.0981 - final_out_acc: 0.8844\n",
      "\n",
      "Epoch 00084: final_out_loss did not improve from 0.08586\n",
      "Epoch 85/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.3532 - out11_loss: 0.0908 - out12_loss: 0.0876 - out13_loss: 0.0874 - final_out_loss: 0.0873 - final_out_acc: 0.8996\n",
      "\n",
      "Epoch 00085: final_out_loss did not improve from 0.08586\n",
      "Epoch 86/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.4149 - out11_loss: 0.1059 - out12_loss: 0.1029 - out13_loss: 0.1031 - final_out_loss: 0.1029 - final_out_acc: 0.8866\n",
      "\n",
      "Epoch 00086: final_out_loss did not improve from 0.08586\n",
      "Epoch 87/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.3822 - out11_loss: 0.0983 - out12_loss: 0.0948 - out13_loss: 0.0946 - final_out_loss: 0.0945 - final_out_acc: 0.8902\n",
      "\n",
      "Epoch 00087: final_out_loss did not improve from 0.08586\n",
      "Epoch 88/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.4046 - out11_loss: 0.1041 - out12_loss: 0.1004 - out13_loss: 0.1001 - final_out_loss: 0.1000 - final_out_acc: 0.8783\n",
      "\n",
      "Epoch 00088: final_out_loss did not improve from 0.08586\n",
      "Epoch 89/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.4000 - out11_loss: 0.1025 - out12_loss: 0.0993 - out13_loss: 0.0991 - final_out_loss: 0.0991 - final_out_acc: 0.8782\n",
      "\n",
      "Epoch 00089: final_out_loss did not improve from 0.08586\n",
      "Epoch 90/200\n",
      "62/62 [==============================] - 14s 223ms/step - loss: 0.4416 - out11_loss: 0.1135 - out12_loss: 0.1096 - out13_loss: 0.1093 - final_out_loss: 0.1092 - final_out_acc: 0.8752\n",
      "\n",
      "Epoch 00090: final_out_loss did not improve from 0.08586\n",
      "Epoch 91/200\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 0.4158 - out11_loss: 0.1067 - out12_loss: 0.1033 - out13_loss: 0.1030 - final_out_loss: 0.1028 - final_out_acc: 0.8841\n",
      "\n",
      "Epoch 00091: final_out_loss did not improve from 0.08586\n",
      "Epoch 92/200\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.3941 - out11_loss: 0.1012 - out12_loss: 0.0978 - out13_loss: 0.0976 - final_out_loss: 0.0975 - final_out_acc: 0.8900\n",
      "\n",
      "Epoch 00092: final_out_loss did not improve from 0.08586\n",
      "Epoch 93/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3722 - out11_loss: 0.0949 - out12_loss: 0.0923 - out13_loss: 0.0926 - final_out_loss: 0.0924 - final_out_acc: 0.9010\n",
      "\n",
      "Epoch 00093: final_out_loss did not improve from 0.08586\n",
      "Epoch 94/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.3752 - out11_loss: 0.0960 - out12_loss: 0.0931 - out13_loss: 0.0931 - final_out_loss: 0.0930 - final_out_acc: 0.8908\n",
      "\n",
      "Epoch 00094: final_out_loss did not improve from 0.08586\n",
      "Epoch 95/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.4350 - out11_loss: 0.1116 - out12_loss: 0.1079 - out13_loss: 0.1078 - final_out_loss: 0.1077 - final_out_acc: 0.8745\n",
      "\n",
      "Epoch 00095: final_out_loss did not improve from 0.08586\n",
      "Epoch 96/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.3664 - out11_loss: 0.0938 - out12_loss: 0.0909 - out13_loss: 0.0909 - final_out_loss: 0.0908 - final_out_acc: 0.8900\n",
      "\n",
      "Epoch 00096: final_out_loss did not improve from 0.08586\n",
      "Epoch 97/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.4194 - out11_loss: 0.1077 - out12_loss: 0.1041 - out13_loss: 0.1039 - final_out_loss: 0.1037 - final_out_acc: 0.8738\n",
      "\n",
      "Epoch 00097: final_out_loss did not improve from 0.08586\n",
      "Epoch 98/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.3724 - out11_loss: 0.0955 - out12_loss: 0.0925 - out13_loss: 0.0923 - final_out_loss: 0.0921 - final_out_acc: 0.8893\n",
      "\n",
      "Epoch 00098: final_out_loss did not improve from 0.08586\n",
      "Epoch 99/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.4068 - out11_loss: 0.1044 - out12_loss: 0.1009 - out13_loss: 0.1008 - final_out_loss: 0.1007 - final_out_acc: 0.8849\n",
      "\n",
      "Epoch 00099: final_out_loss did not improve from 0.08586\n",
      "Epoch 100/200\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 0.3435 - out11_loss: 0.0881 - out12_loss: 0.0852 - out13_loss: 0.0851 - final_out_loss: 0.0850 - final_out_acc: 0.9080\n",
      "\n",
      "Epoch 00100: final_out_loss did not improve from 0.08586\n",
      "Epoch 101/200\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.4122 - out11_loss: 0.1056 - out12_loss: 0.1023 - out13_loss: 0.1022 - final_out_loss: 0.1021 - final_out_acc: 0.8826\n",
      "\n",
      "Epoch 00101: final_out_loss did not improve from 0.08586\n",
      "Epoch 102/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3804 - out11_loss: 0.0975 - out12_loss: 0.0944 - out13_loss: 0.0942 - final_out_loss: 0.0941 - final_out_acc: 0.8869\n",
      "\n",
      "Epoch 00102: final_out_loss did not improve from 0.08586\n",
      "Epoch 103/200\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 0.3942 - out11_loss: 0.1014 - out12_loss: 0.0978 - out13_loss: 0.0976 - final_out_loss: 0.0974 - final_out_acc: 0.8881\n",
      "\n",
      "Epoch 00103: final_out_loss did not improve from 0.08586\n",
      "Epoch 104/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3993 - out11_loss: 0.1021 - out12_loss: 0.0990 - out13_loss: 0.0991 - final_out_loss: 0.0990 - final_out_acc: 0.8839\n",
      "\n",
      "Epoch 00104: final_out_loss did not improve from 0.08586\n",
      "Epoch 105/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.3805 - out11_loss: 0.0972 - out12_loss: 0.0944 - out13_loss: 0.0945 - final_out_loss: 0.0944 - final_out_acc: 0.8895\n",
      "\n",
      "Epoch 00105: final_out_loss did not improve from 0.08586\n",
      "Epoch 106/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.4481 - out11_loss: 0.1146 - out12_loss: 0.1114 - out13_loss: 0.1111 - final_out_loss: 0.1110 - final_out_acc: 0.8784\n",
      "\n",
      "Epoch 00106: final_out_loss did not improve from 0.08586\n",
      "Epoch 107/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.3961 - out11_loss: 0.1012 - out12_loss: 0.0984 - out13_loss: 0.0983 - final_out_loss: 0.0982 - final_out_acc: 0.8825\n",
      "\n",
      "Epoch 00107: final_out_loss did not improve from 0.08586\n",
      "Epoch 108/200\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 0.3978 - out11_loss: 0.1020 - out12_loss: 0.0988 - out13_loss: 0.0986 - final_out_loss: 0.0985 - final_out_acc: 0.8895\n",
      "\n",
      "Epoch 00108: final_out_loss did not improve from 0.08586\n",
      "Epoch 109/200\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 0.3864 - out11_loss: 0.0991 - out12_loss: 0.0959 - out13_loss: 0.0957 - final_out_loss: 0.0957 - final_out_acc: 0.8848\n",
      "\n",
      "Epoch 00109: final_out_loss did not improve from 0.08586\n",
      "Epoch 110/200\n",
      "62/62 [==============================] - 14s 223ms/step - loss: 0.3956 - out11_loss: 0.1013 - out12_loss: 0.0983 - out13_loss: 0.0980 - final_out_loss: 0.0979 - final_out_acc: 0.8849\n",
      "\n",
      "Epoch 00110: final_out_loss did not improve from 0.08586\n",
      "Epoch 111/200\n",
      "62/62 [==============================] - 13s 208ms/step - loss: 0.3628 - out11_loss: 0.0931 - out12_loss: 0.0901 - out13_loss: 0.0899 - final_out_loss: 0.0897 - final_out_acc: 0.8959\n",
      "\n",
      "Epoch 00111: final_out_loss did not improve from 0.08586\n",
      "Epoch 112/200\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 0.3697 - out11_loss: 0.0949 - out12_loss: 0.0918 - out13_loss: 0.0915 - final_out_loss: 0.0915 - final_out_acc: 0.8966\n",
      "\n",
      "Epoch 00112: final_out_loss did not improve from 0.08586\n",
      "Epoch 113/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3642 - out11_loss: 0.0932 - out12_loss: 0.0905 - out13_loss: 0.0903 - final_out_loss: 0.0902 - final_out_acc: 0.8941\n",
      "\n",
      "Epoch 00113: final_out_loss did not improve from 0.08586\n",
      "Epoch 114/200\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.3305 - out11_loss: 0.0843 - out12_loss: 0.0821 - out13_loss: 0.0821 - final_out_loss: 0.0820 - final_out_acc: 0.9087\n",
      "\n",
      "Epoch 00114: final_out_loss improved from 0.08586 to 0.08158, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 115/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.4077 - out11_loss: 0.1045 - out12_loss: 0.1011 - out13_loss: 0.1011 - final_out_loss: 0.1010 - final_out_acc: 0.8829\n",
      "\n",
      "Epoch 00115: final_out_loss did not improve from 0.08158\n",
      "Epoch 116/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.3662 - out11_loss: 0.0937 - out12_loss: 0.0909 - out13_loss: 0.0909 - final_out_loss: 0.0908 - final_out_acc: 0.8984\n",
      "\n",
      "Epoch 00116: final_out_loss did not improve from 0.08158\n",
      "Epoch 117/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.3725 - out11_loss: 0.0948 - out12_loss: 0.0923 - out13_loss: 0.0928 - final_out_loss: 0.0926 - final_out_acc: 0.8932\n",
      "\n",
      "Epoch 00117: final_out_loss did not improve from 0.08158\n",
      "Epoch 118/200\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 0.3448 - out11_loss: 0.0878 - out12_loss: 0.0854 - out13_loss: 0.0858 - final_out_loss: 0.0858 - final_out_acc: 0.9074\n",
      "\n",
      "Epoch 00118: final_out_loss did not improve from 0.08158\n",
      "Epoch 119/200\n",
      "62/62 [==============================] - 14s 224ms/step - loss: 0.3885 - out11_loss: 0.0991 - out12_loss: 0.0965 - out13_loss: 0.0964 - final_out_loss: 0.0964 - final_out_acc: 0.8967\n",
      "\n",
      "Epoch 00119: final_out_loss did not improve from 0.08158\n",
      "Epoch 120/200\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 0.3510 - out11_loss: 0.0894 - out12_loss: 0.0872 - out13_loss: 0.0873 - final_out_loss: 0.0872 - final_out_acc: 0.8989\n",
      "\n",
      "Epoch 00120: final_out_loss did not improve from 0.08158\n",
      "Epoch 121/200\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.3876 - out11_loss: 0.0990 - out12_loss: 0.0962 - out13_loss: 0.0962 - final_out_loss: 0.0961 - final_out_acc: 0.8921\n",
      "\n",
      "Epoch 00121: final_out_loss did not improve from 0.08158\n",
      "Epoch 122/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3620 - out11_loss: 0.0925 - out12_loss: 0.0899 - out13_loss: 0.0899 - final_out_loss: 0.0897 - final_out_acc: 0.8922\n",
      "\n",
      "Epoch 00122: final_out_loss did not improve from 0.08158\n",
      "Epoch 123/200\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.3282 - out11_loss: 0.0845 - out12_loss: 0.0814 - out13_loss: 0.0812 - final_out_loss: 0.0811 - final_out_acc: 0.9068\n",
      "\n",
      "Epoch 00123: final_out_loss did not improve from 0.08158\n",
      "Epoch 124/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3911 - out11_loss: 0.1000 - out12_loss: 0.0971 - out13_loss: 0.0970 - final_out_loss: 0.0969 - final_out_acc: 0.8849\n",
      "\n",
      "Epoch 00124: final_out_loss did not improve from 0.08158\n",
      "Epoch 125/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.3525 - out11_loss: 0.0897 - out12_loss: 0.0876 - out13_loss: 0.0876 - final_out_loss: 0.0875 - final_out_acc: 0.8890\n",
      "\n",
      "Epoch 00125: final_out_loss did not improve from 0.08158\n",
      "Epoch 126/200\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 0.3335 - out11_loss: 0.0852 - out12_loss: 0.0827 - out13_loss: 0.0828 - final_out_loss: 0.0828 - final_out_acc: 0.9070\n",
      "\n",
      "Epoch 00126: final_out_loss did not improve from 0.08158\n",
      "Epoch 127/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.3408 - out11_loss: 0.0873 - out12_loss: 0.0846 - out13_loss: 0.0844 - final_out_loss: 0.0844 - final_out_acc: 0.8981\n",
      "\n",
      "Epoch 00127: final_out_loss did not improve from 0.08158\n",
      "Epoch 128/200\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 0.3622 - out11_loss: 0.0927 - out12_loss: 0.0900 - out13_loss: 0.0899 - final_out_loss: 0.0897 - final_out_acc: 0.8891\n",
      "\n",
      "Epoch 00128: final_out_loss did not improve from 0.08158\n",
      "Epoch 129/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.3574 - out11_loss: 0.0914 - out12_loss: 0.0887 - out13_loss: 0.0886 - final_out_loss: 0.0886 - final_out_acc: 0.8923\n",
      "\n",
      "Epoch 00129: final_out_loss did not improve from 0.08158\n",
      "Epoch 130/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.3910 - out11_loss: 0.1001 - out12_loss: 0.0972 - out13_loss: 0.0969 - final_out_loss: 0.0969 - final_out_acc: 0.8867\n",
      "\n",
      "Epoch 00130: final_out_loss did not improve from 0.08158\n",
      "Epoch 131/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3577 - out11_loss: 0.0916 - out12_loss: 0.0889 - out13_loss: 0.0887 - final_out_loss: 0.0885 - final_out_acc: 0.8908\n",
      "\n",
      "Epoch 00131: final_out_loss did not improve from 0.08158\n",
      "Epoch 132/200\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.3877 - out11_loss: 0.0991 - out12_loss: 0.0963 - out13_loss: 0.0962 - final_out_loss: 0.0962 - final_out_acc: 0.8846\n",
      "\n",
      "Epoch 00132: final_out_loss did not improve from 0.08158\n",
      "Epoch 133/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3736 - out11_loss: 0.0953 - out12_loss: 0.0928 - out13_loss: 0.0928 - final_out_loss: 0.0927 - final_out_acc: 0.8904\n",
      "\n",
      "Epoch 00133: final_out_loss did not improve from 0.08158\n",
      "Epoch 134/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.3372 - out11_loss: 0.0860 - out12_loss: 0.0838 - out13_loss: 0.0838 - final_out_loss: 0.0836 - final_out_acc: 0.9019\n",
      "\n",
      "Epoch 00134: final_out_loss did not improve from 0.08158\n",
      "Epoch 135/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.3801 - out11_loss: 0.0972 - out12_loss: 0.0943 - out13_loss: 0.0944 - final_out_loss: 0.0943 - final_out_acc: 0.8920\n",
      "\n",
      "Epoch 00135: final_out_loss did not improve from 0.08158\n",
      "Epoch 136/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.3687 - out11_loss: 0.0944 - out12_loss: 0.0916 - out13_loss: 0.0914 - final_out_loss: 0.0913 - final_out_acc: 0.8942\n",
      "\n",
      "Epoch 00136: final_out_loss did not improve from 0.08158\n",
      "Epoch 137/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.4062 - out11_loss: 0.1041 - out12_loss: 0.1009 - out13_loss: 0.1006 - final_out_loss: 0.1006 - final_out_acc: 0.8793\n",
      "\n",
      "Epoch 00137: final_out_loss did not improve from 0.08158\n",
      "Epoch 138/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.4000 - out11_loss: 0.1023 - out12_loss: 0.0993 - out13_loss: 0.0992 - final_out_loss: 0.0991 - final_out_acc: 0.8784\n",
      "\n",
      "Epoch 00138: final_out_loss did not improve from 0.08158\n",
      "Epoch 139/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.4265 - out11_loss: 0.1090 - out12_loss: 0.1060 - out13_loss: 0.1058 - final_out_loss: 0.1057 - final_out_acc: 0.8696\n",
      "\n",
      "Epoch 00139: final_out_loss did not improve from 0.08158\n",
      "Epoch 140/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.3779 - out11_loss: 0.0965 - out12_loss: 0.0939 - out13_loss: 0.0938 - final_out_loss: 0.0938 - final_out_acc: 0.8881\n",
      "\n",
      "Epoch 00140: final_out_loss did not improve from 0.08158\n",
      "Epoch 141/200\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 0.3825 - out11_loss: 0.0978 - out12_loss: 0.0950 - out13_loss: 0.0948 - final_out_loss: 0.0948 - final_out_acc: 0.8831\n",
      "\n",
      "Epoch 00141: final_out_loss did not improve from 0.08158\n",
      "Epoch 142/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3473 - out11_loss: 0.0889 - out12_loss: 0.0864 - out13_loss: 0.0860 - final_out_loss: 0.0860 - final_out_acc: 0.8995\n",
      "\n",
      "Epoch 00142: final_out_loss did not improve from 0.08158\n",
      "Epoch 143/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.4105 - out11_loss: 0.1054 - out12_loss: 0.1020 - out13_loss: 0.1016 - final_out_loss: 0.1015 - final_out_acc: 0.8780\n",
      "\n",
      "Epoch 00143: final_out_loss did not improve from 0.08158\n",
      "Epoch 144/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.3820 - out11_loss: 0.0979 - out12_loss: 0.0949 - out13_loss: 0.0947 - final_out_loss: 0.0945 - final_out_acc: 0.8827\n",
      "\n",
      "Epoch 00144: final_out_loss did not improve from 0.08158\n",
      "Epoch 145/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.3813 - out11_loss: 0.0979 - out12_loss: 0.0946 - out13_loss: 0.0944 - final_out_loss: 0.0943 - final_out_acc: 0.8848\n",
      "\n",
      "Epoch 00145: final_out_loss did not improve from 0.08158\n",
      "Epoch 146/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.3614 - out11_loss: 0.0927 - out12_loss: 0.0898 - out13_loss: 0.0895 - final_out_loss: 0.0894 - final_out_acc: 0.8914\n",
      "\n",
      "Epoch 00146: final_out_loss did not improve from 0.08158\n",
      "Epoch 147/200\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 0.3391 - out11_loss: 0.0867 - out12_loss: 0.0843 - out13_loss: 0.0842 - final_out_loss: 0.0840 - final_out_acc: 0.9011\n",
      "\n",
      "Epoch 00147: final_out_loss did not improve from 0.08158\n",
      "Epoch 148/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.4020 - out11_loss: 0.1030 - out12_loss: 0.0998 - out13_loss: 0.0997 - final_out_loss: 0.0995 - final_out_acc: 0.8821\n",
      "\n",
      "Epoch 00148: final_out_loss did not improve from 0.08158\n",
      "Epoch 149/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.3458 - out11_loss: 0.0891 - out12_loss: 0.0858 - out13_loss: 0.0856 - final_out_loss: 0.0854 - final_out_acc: 0.9013\n",
      "\n",
      "Epoch 00149: final_out_loss did not improve from 0.08158\n",
      "Epoch 150/200\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 0.4195 - out11_loss: 0.1076 - out12_loss: 0.1046 - out13_loss: 0.1038 - final_out_loss: 0.1036 - final_out_acc: 0.8788\n",
      "\n",
      "Epoch 00150: final_out_loss did not improve from 0.08158\n",
      "Epoch 151/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3586 - out11_loss: 0.0920 - out12_loss: 0.0890 - out13_loss: 0.0888 - final_out_loss: 0.0888 - final_out_acc: 0.8937\n",
      "\n",
      "Epoch 00151: final_out_loss did not improve from 0.08158\n",
      "Epoch 152/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.5362 - out11_loss: 0.1411 - out12_loss: 0.1329 - out13_loss: 0.1302 - final_out_loss: 0.1320 - final_out_acc: 0.8666\n",
      "\n",
      "Epoch 00152: final_out_loss did not improve from 0.08158\n",
      "Epoch 153/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.4307 - out11_loss: 0.1142 - out12_loss: 0.1050 - out13_loss: 0.1059 - final_out_loss: 0.1057 - final_out_acc: 0.8919\n",
      "\n",
      "Epoch 00153: final_out_loss did not improve from 0.08158\n",
      "Epoch 154/200\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 0.4094 - out11_loss: 0.1092 - out12_loss: 0.1004 - out13_loss: 0.1000 - final_out_loss: 0.0999 - final_out_acc: 0.8909\n",
      "\n",
      "Epoch 00154: final_out_loss did not improve from 0.08158\n",
      "Epoch 155/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.3771 - out11_loss: 0.1005 - out12_loss: 0.0924 - out13_loss: 0.0922 - final_out_loss: 0.0921 - final_out_acc: 0.8982\n",
      "\n",
      "Epoch 00155: final_out_loss did not improve from 0.08158\n",
      "Epoch 156/200\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 0.3815 - out11_loss: 0.1013 - out12_loss: 0.0936 - out13_loss: 0.0933 - final_out_loss: 0.0932 - final_out_acc: 0.8888\n",
      "\n",
      "Epoch 00156: final_out_loss did not improve from 0.08158\n",
      "Epoch 157/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.4117 - out11_loss: 0.1093 - out12_loss: 0.1011 - out13_loss: 0.1007 - final_out_loss: 0.1006 - final_out_acc: 0.8834\n",
      "\n",
      "Epoch 00157: final_out_loss did not improve from 0.08158\n",
      "Epoch 158/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.4063 - out11_loss: 0.1082 - out12_loss: 0.0998 - out13_loss: 0.0992 - final_out_loss: 0.0991 - final_out_acc: 0.8846\n",
      "\n",
      "Epoch 00158: final_out_loss did not improve from 0.08158\n",
      "Epoch 159/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.3917 - out11_loss: 0.1043 - out12_loss: 0.0961 - out13_loss: 0.0957 - final_out_loss: 0.0956 - final_out_acc: 0.8898\n",
      "\n",
      "Epoch 00159: final_out_loss did not improve from 0.08158\n",
      "Epoch 160/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.3786 - out11_loss: 0.1016 - out12_loss: 0.0928 - out13_loss: 0.0921 - final_out_loss: 0.0922 - final_out_acc: 0.8940\n",
      "\n",
      "Epoch 00160: final_out_loss did not improve from 0.08158\n",
      "Epoch 161/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.3906 - out11_loss: 0.1035 - out12_loss: 0.0955 - out13_loss: 0.0958 - final_out_loss: 0.0958 - final_out_acc: 0.8964\n",
      "\n",
      "Epoch 00161: final_out_loss did not improve from 0.08158\n",
      "Epoch 162/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3974 - out11_loss: 0.1055 - out12_loss: 0.0976 - out13_loss: 0.0971 - final_out_loss: 0.0971 - final_out_acc: 0.8928\n",
      "\n",
      "Epoch 00162: final_out_loss did not improve from 0.08158\n",
      "Epoch 163/200\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.4003 - out11_loss: 0.1065 - out12_loss: 0.0983 - out13_loss: 0.0978 - final_out_loss: 0.0977 - final_out_acc: 0.8930\n",
      "\n",
      "Epoch 00163: final_out_loss did not improve from 0.08158\n",
      "Epoch 164/200\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 0.3797 - out11_loss: 0.1016 - out12_loss: 0.0926 - out13_loss: 0.0927 - final_out_loss: 0.0928 - final_out_acc: 0.8990\n",
      "\n",
      "Epoch 00164: final_out_loss did not improve from 0.08158\n",
      "Epoch 165/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.3478 - out11_loss: 0.0918 - out12_loss: 0.0857 - out13_loss: 0.0853 - final_out_loss: 0.0852 - final_out_acc: 0.9037\n",
      "\n",
      "Epoch 00165: final_out_loss improved from 0.08158 to 0.08127, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 166/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.3378 - out11_loss: 0.0902 - out12_loss: 0.0827 - out13_loss: 0.0825 - final_out_loss: 0.0824 - final_out_acc: 0.9093\n",
      "\n",
      "Epoch 00166: final_out_loss improved from 0.08127 to 0.07942, saving model to trained_model/DRIVE/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 167/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.3643 - out11_loss: 0.0957 - out12_loss: 0.0899 - out13_loss: 0.0894 - final_out_loss: 0.0893 - final_out_acc: 0.8991\n",
      "\n",
      "Epoch 00167: final_out_loss did not improve from 0.07942\n",
      "Epoch 168/200\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 0.4045 - out11_loss: 0.1072 - out12_loss: 0.0996 - out13_loss: 0.0989 - final_out_loss: 0.0988 - final_out_acc: 0.8851\n",
      "\n",
      "Epoch 00168: final_out_loss did not improve from 0.07942\n",
      "Epoch 169/200\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 0.3806 - out11_loss: 0.1010 - out12_loss: 0.0935 - out13_loss: 0.0931 - final_out_loss: 0.0931 - final_out_acc: 0.8878\n",
      "\n",
      "Epoch 00169: final_out_loss did not improve from 0.07942\n",
      "Epoch 170/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.4263 - out11_loss: 0.1134 - out12_loss: 0.1048 - out13_loss: 0.1041 - final_out_loss: 0.1040 - final_out_acc: 0.8799\n",
      "\n",
      "Epoch 00170: final_out_loss did not improve from 0.07942\n",
      "Epoch 171/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3789 - out11_loss: 0.1008 - out12_loss: 0.0932 - out13_loss: 0.0925 - final_out_loss: 0.0924 - final_out_acc: 0.8907\n",
      "\n",
      "Epoch 00171: final_out_loss did not improve from 0.07942\n",
      "Epoch 172/200\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 0.4183 - out11_loss: 0.1114 - out12_loss: 0.1030 - out13_loss: 0.1020 - final_out_loss: 0.1019 - final_out_acc: 0.8796\n",
      "\n",
      "Epoch 00172: final_out_loss did not improve from 0.07942\n",
      "Epoch 173/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.3718 - out11_loss: 0.0989 - out12_loss: 0.0916 - out13_loss: 0.0907 - final_out_loss: 0.0906 - final_out_acc: 0.8930\n",
      "\n",
      "Epoch 00173: final_out_loss did not improve from 0.07942\n",
      "Epoch 174/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.3576 - out11_loss: 0.0950 - out12_loss: 0.0881 - out13_loss: 0.0873 - final_out_loss: 0.0872 - final_out_acc: 0.8960\n",
      "\n",
      "Epoch 00174: final_out_loss did not improve from 0.07942\n",
      "Epoch 175/200\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 0.3714 - out11_loss: 0.0993 - out12_loss: 0.0913 - out13_loss: 0.0904 - final_out_loss: 0.0903 - final_out_acc: 0.8989\n",
      "\n",
      "Epoch 00175: final_out_loss did not improve from 0.07942\n",
      "Epoch 176/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.3993 - out11_loss: 0.1065 - out12_loss: 0.0982 - out13_loss: 0.0974 - final_out_loss: 0.0972 - final_out_acc: 0.8847\n",
      "\n",
      "Epoch 00176: final_out_loss did not improve from 0.07942\n",
      "Epoch 177/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.4235 - out11_loss: 0.1128 - out12_loss: 0.1043 - out13_loss: 0.1033 - final_out_loss: 0.1032 - final_out_acc: 0.8743\n",
      "\n",
      "Epoch 00177: final_out_loss did not improve from 0.07942\n",
      "Epoch 178/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.4252 - out11_loss: 0.1128 - out12_loss: 0.1047 - out13_loss: 0.1039 - final_out_loss: 0.1038 - final_out_acc: 0.8714\n",
      "\n",
      "Epoch 00178: final_out_loss did not improve from 0.07942\n",
      "Epoch 179/200\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 0.4119 - out11_loss: 0.1097 - out12_loss: 0.1014 - out13_loss: 0.1004 - final_out_loss: 0.1003 - final_out_acc: 0.8778\n",
      "\n",
      "Epoch 00179: final_out_loss did not improve from 0.07942\n",
      "Epoch 180/200\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 0.3860 - out11_loss: 0.1030 - out12_loss: 0.0949 - out13_loss: 0.0942 - final_out_loss: 0.0939 - final_out_acc: 0.8930\n",
      "\n",
      "Epoch 00180: final_out_loss did not improve from 0.07942\n",
      "Epoch 181/200\n",
      "62/62 [==============================] - 14s 218ms/step - loss: 0.4056 - out11_loss: 0.1075 - out12_loss: 0.0997 - out13_loss: 0.0992 - final_out_loss: 0.0992 - final_out_acc: 0.8875\n",
      "\n",
      "Epoch 00181: final_out_loss did not improve from 0.07942\n",
      "Epoch 182/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.4002 - out11_loss: 0.1065 - out12_loss: 0.0985 - out13_loss: 0.0976 - final_out_loss: 0.0976 - final_out_acc: 0.8812\n",
      "\n",
      "Epoch 00182: final_out_loss did not improve from 0.07942\n",
      "Epoch 183/200\n",
      "62/62 [==============================] - 14s 220ms/step - loss: 0.3812 - out11_loss: 0.1015 - out12_loss: 0.0937 - out13_loss: 0.0930 - final_out_loss: 0.0929 - final_out_acc: 0.8855\n",
      "\n",
      "Epoch 00183: final_out_loss did not improve from 0.07942\n",
      "Epoch 184/200\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 0.3995 - out11_loss: 0.1062 - out12_loss: 0.0984 - out13_loss: 0.0975 - final_out_loss: 0.0974 - final_out_acc: 0.8825\n",
      "\n",
      "Epoch 00184: final_out_loss did not improve from 0.07942\n",
      "Epoch 185/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.3823 - out11_loss: 0.1017 - out12_loss: 0.0942 - out13_loss: 0.0933 - final_out_loss: 0.0931 - final_out_acc: 0.8877\n",
      "\n",
      "Epoch 00185: final_out_loss did not improve from 0.07942\n",
      "Epoch 186/200\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 0.3796 - out11_loss: 0.1009 - out12_loss: 0.0934 - out13_loss: 0.0927 - final_out_loss: 0.0926 - final_out_acc: 0.8887\n",
      "\n",
      "Epoch 00186: final_out_loss did not improve from 0.07942\n",
      "Epoch 187/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.4121 - out11_loss: 0.1094 - out12_loss: 0.1015 - out13_loss: 0.1007 - final_out_loss: 0.1005 - final_out_acc: 0.8746\n",
      "\n",
      "Epoch 00187: final_out_loss did not improve from 0.07942\n",
      "Epoch 188/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.3979 - out11_loss: 0.1059 - out12_loss: 0.0980 - out13_loss: 0.0971 - final_out_loss: 0.0969 - final_out_acc: 0.8851\n",
      "\n",
      "Epoch 00188: final_out_loss did not improve from 0.07942\n",
      "Epoch 189/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3791 - out11_loss: 0.1005 - out12_loss: 0.0934 - out13_loss: 0.0926 - final_out_loss: 0.0925 - final_out_acc: 0.8817\n",
      "\n",
      "Epoch 00189: final_out_loss did not improve from 0.07942\n",
      "Epoch 190/200\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 0.4171 - out11_loss: 0.1110 - out12_loss: 0.1028 - out13_loss: 0.1017 - final_out_loss: 0.1016 - final_out_acc: 0.8720\n",
      "\n",
      "Epoch 00190: final_out_loss did not improve from 0.07942\n",
      "Epoch 191/200\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 0.3686 - out11_loss: 0.0980 - out12_loss: 0.0905 - out13_loss: 0.0901 - final_out_loss: 0.0900 - final_out_acc: 0.8943\n",
      "\n",
      "Epoch 00191: final_out_loss did not improve from 0.07942\n",
      "Epoch 192/200\n",
      "62/62 [==============================] - 14s 222ms/step - loss: 0.3758 - out11_loss: 0.1002 - out12_loss: 0.0924 - out13_loss: 0.0916 - final_out_loss: 0.0915 - final_out_acc: 0.8943\n",
      "\n",
      "Epoch 00192: final_out_loss did not improve from 0.07942\n",
      "Epoch 193/200\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 0.3778 - out11_loss: 0.1002 - out12_loss: 0.0931 - out13_loss: 0.0923 - final_out_loss: 0.0922 - final_out_acc: 0.8903\n",
      "\n",
      "Epoch 00193: final_out_loss did not improve from 0.07942\n",
      "Epoch 194/200\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 0.4037 - out11_loss: 0.1073 - out12_loss: 0.0995 - out13_loss: 0.0985 - final_out_loss: 0.0984 - final_out_acc: 0.8820\n",
      "\n",
      "Epoch 00194: final_out_loss did not improve from 0.07942\n",
      "Epoch 195/200\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 0.3806 - out11_loss: 0.1012 - out12_loss: 0.0938 - out13_loss: 0.0929 - final_out_loss: 0.0927 - final_out_acc: 0.8917\n",
      "\n",
      "Epoch 00195: final_out_loss did not improve from 0.07942\n",
      "Epoch 196/200\n",
      "62/62 [==============================] - 13s 218ms/step - loss: 0.3487 - out11_loss: 0.0927 - out12_loss: 0.0859 - out13_loss: 0.0851 - final_out_loss: 0.0850 - final_out_acc: 0.9074\n",
      "\n",
      "Epoch 00196: final_out_loss did not improve from 0.07942\n",
      "Epoch 197/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.3984 - out11_loss: 0.1062 - out12_loss: 0.0979 - out13_loss: 0.0972 - final_out_loss: 0.0971 - final_out_acc: 0.8883\n",
      "\n",
      "Epoch 00197: final_out_loss did not improve from 0.07942\n",
      "Epoch 198/200\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 0.3754 - out11_loss: 0.0999 - out12_loss: 0.0924 - out13_loss: 0.0916 - final_out_loss: 0.0915 - final_out_acc: 0.8885\n",
      "\n",
      "Epoch 00198: final_out_loss did not improve from 0.07942\n",
      "Epoch 199/200\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 0.4072 - out11_loss: 0.1084 - out12_loss: 0.1003 - out13_loss: 0.0994 - final_out_loss: 0.0992 - final_out_acc: 0.8816\n",
      "\n",
      "Epoch 00199: final_out_loss did not improve from 0.07942\n",
      "Epoch 200/200\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 0.3926 - out11_loss: 0.1043 - out12_loss: 0.0967 - out13_loss: 0.0959 - final_out_loss: 0.0957 - final_out_acc: 0.8861\n",
      "\n",
      "Epoch 00200: final_out_loss did not improve from 0.07942\n"
     ]
    }
   ],
   "source": [
    "############Training\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend import tensorflow_backend\n",
    "import os\n",
    "from train import train\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "session = tf.Session(config=config)\n",
    "tensorflow_backend.set_session(session)\n",
    "\n",
    "\n",
    "#epochs>100 will be enough, but slower\n",
    "#Training may be unstable due to random initialization,\n",
    "#Try it again if out2_auc doesn't increase.\n",
    "train(iteration=3, DATASET='DRIVE', # DRIVE, CHASEDB1 or STARE\n",
    "       batch_size=32, epochs=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/li/anaconda3/envs/univ/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/li/anaconda3/envs/univ/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model : Final_Emer_Iteration_3_cropsize_128_epochs_200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [28:17<00:00, 72.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " out4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under the ROC curve: 0.9815694486607786\n",
      "\n",
      "Area under Precision-Recall curve: 0.915058296196211\n",
      "\n",
      "Confusion matrix:  Costum threshold (for positive) of 0.5\n",
      "[[3907925   57955]\n",
      " [ 137549  434714]]\n",
      "Global Accuracy: 0.9569198238133968\n",
      "Specificity: 0.985386597678195\n",
      "Sensitivity: 0.7596402353463355\n",
      "Precision: 0.8823652391362152\n",
      "\n",
      "Jaccard similarity score: 0.9569198238133968\n",
      "\n",
      "F1 score (F-measure): 0.816416447247336\n"
     ]
    }
   ],
   "source": [
    "############Test\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend import tensorflow_backend\n",
    "import os\n",
    "from predict import predict\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "session = tf.Session(config=config)\n",
    "tensorflow_backend.set_session(session)\n",
    "\n",
    "\n",
    "#stride_size = 3 will be better, but slower\n",
    "predict(batch_size=32, epochs=200, iteration=3, stride_size=3, DATASET='DRIVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
