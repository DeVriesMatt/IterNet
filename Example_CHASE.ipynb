{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Final_Emer_Iteration_3_cropsize_128_epochs_200\n",
      "WARNING:tensorflow:From /home/li/anaconda3/envs/univ/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/li/anaconda3/envs/univ/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/li/anaconda3/envs/univ/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li/anaconda3/envs/univ/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "62/62 [==============================] - 39s 633ms/step - loss: 1.6147 - out11_loss: 0.3713 - out12_loss: 0.3945 - out13_loss: 0.4272 - final_out_loss: 0.4216 - final_out_acc: 0.9111\n",
      "\n",
      "Epoch 00001: final_out_loss improved from inf to 0.43531, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 2/200\n",
      "62/62 [==============================] - 30s 484ms/step - loss: 0.7619 - out11_loss: 0.1862 - out12_loss: 0.1888 - out13_loss: 0.1911 - final_out_loss: 0.1957 - final_out_acc: 0.9190\n",
      "\n",
      "Epoch 00002: final_out_loss improved from 0.43531 to 0.19627, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 3/200\n",
      "62/62 [==============================] - 28s 455ms/step - loss: 0.7587 - out11_loss: 0.1886 - out12_loss: 0.1893 - out13_loss: 0.1901 - final_out_loss: 0.1908 - final_out_acc: 0.9205\n",
      "\n",
      "Epoch 00003: final_out_loss improved from 0.19627 to 0.18605, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 4/200\n",
      "62/62 [==============================] - 31s 499ms/step - loss: 0.8182 - out11_loss: 0.2039 - out12_loss: 0.2039 - out13_loss: 0.2047 - final_out_loss: 0.2056 - final_out_acc: 0.9145\n",
      "\n",
      "Epoch 00004: final_out_loss did not improve from 0.18605\n",
      "Epoch 5/200\n",
      "62/62 [==============================] - 28s 449ms/step - loss: 0.8464 - out11_loss: 0.2107 - out12_loss: 0.2112 - out13_loss: 0.2119 - final_out_loss: 0.2126 - final_out_acc: 0.9115\n",
      "\n",
      "Epoch 00005: final_out_loss did not improve from 0.18605\n",
      "Epoch 6/200\n",
      "62/62 [==============================] - 30s 490ms/step - loss: 0.9001 - out11_loss: 0.2242 - out12_loss: 0.2245 - out13_loss: 0.2254 - final_out_loss: 0.2260 - final_out_acc: 0.9028\n",
      "\n",
      "Epoch 00006: final_out_loss did not improve from 0.18605\n",
      "Epoch 7/200\n",
      "62/62 [==============================] - 29s 470ms/step - loss: 0.8984 - out11_loss: 0.2247 - out12_loss: 0.2244 - out13_loss: 0.2240 - final_out_loss: 0.2253 - final_out_acc: 0.9023\n",
      "\n",
      "Epoch 00007: final_out_loss did not improve from 0.18605\n",
      "Epoch 8/200\n",
      "62/62 [==============================] - 30s 485ms/step - loss: 0.8515 - out11_loss: 0.2305 - out12_loss: 0.2237 - out13_loss: 0.1966 - final_out_loss: 0.2006 - final_out_acc: 0.9022\n",
      "\n",
      "Epoch 00008: final_out_loss did not improve from 0.18605\n",
      "Epoch 9/200\n",
      "62/62 [==============================] - 29s 472ms/step - loss: 0.6636 - out11_loss: 0.2209 - out12_loss: 0.1589 - out13_loss: 0.1422 - final_out_loss: 0.1416 - final_out_acc: 0.9182\n",
      "\n",
      "Epoch 00009: final_out_loss improved from 0.18605 to 0.14680, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 10/200\n",
      "62/62 [==============================] - 29s 469ms/step - loss: 0.5422 - out11_loss: 0.1948 - out12_loss: 0.1169 - out13_loss: 0.1155 - final_out_loss: 0.1150 - final_out_acc: 0.9358\n",
      "\n",
      "Epoch 00010: final_out_loss improved from 0.14680 to 0.11721, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 11/200\n",
      "62/62 [==============================] - 29s 463ms/step - loss: 0.5458 - out11_loss: 0.2021 - out12_loss: 0.1152 - out13_loss: 0.1143 - final_out_loss: 0.1142 - final_out_acc: 0.9381\n",
      "\n",
      "Epoch 00011: final_out_loss improved from 0.11721 to 0.11350, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 12/200\n",
      "62/62 [==============================] - 29s 463ms/step - loss: 0.5681 - out11_loss: 0.2027 - out12_loss: 0.1226 - out13_loss: 0.1215 - final_out_loss: 0.1213 - final_out_acc: 0.9317\n",
      "\n",
      "Epoch 00012: final_out_loss did not improve from 0.11350\n",
      "Epoch 13/200\n",
      "62/62 [==============================] - 30s 480ms/step - loss: 0.6234 - out11_loss: 0.2112 - out12_loss: 0.1378 - out13_loss: 0.1372 - final_out_loss: 0.1372 - final_out_acc: 0.9205\n",
      "\n",
      "Epoch 00013: final_out_loss did not improve from 0.11350\n",
      "Epoch 14/200\n",
      "62/62 [==============================] - 29s 464ms/step - loss: 0.5498 - out11_loss: 0.1954 - out12_loss: 0.1185 - out13_loss: 0.1181 - final_out_loss: 0.1178 - final_out_acc: 0.9295\n",
      "\n",
      "Epoch 00014: final_out_loss did not improve from 0.11350\n",
      "Epoch 15/200\n",
      "62/62 [==============================] - 30s 484ms/step - loss: 0.5402 - out11_loss: 0.1899 - out12_loss: 0.1173 - out13_loss: 0.1166 - final_out_loss: 0.1165 - final_out_acc: 0.9314\n",
      "\n",
      "Epoch 00015: final_out_loss did not improve from 0.11350\n",
      "Epoch 16/200\n",
      "62/62 [==============================] - 28s 448ms/step - loss: 0.4604 - out11_loss: 0.1471 - out12_loss: 0.1055 - out13_loss: 0.1042 - final_out_loss: 0.1037 - final_out_acc: 0.9400\n",
      "\n",
      "Epoch 00016: final_out_loss improved from 0.11350 to 0.10667, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 17/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.4543 - out11_loss: 0.1251 - out12_loss: 0.1103 - out13_loss: 0.1096 - final_out_loss: 0.1092 - final_out_acc: 0.9365\n",
      "\n",
      "Epoch 00017: final_out_loss did not improve from 0.10667\n",
      "Epoch 18/200\n",
      "62/62 [==============================] - 28s 457ms/step - loss: 0.4221 - out11_loss: 0.1121 - out12_loss: 0.1037 - out13_loss: 0.1033 - final_out_loss: 0.1030 - final_out_acc: 0.9403\n",
      "\n",
      "Epoch 00018: final_out_loss improved from 0.10667 to 0.10089, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 19/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.4066 - out11_loss: 0.1078 - out12_loss: 0.1003 - out13_loss: 0.0993 - final_out_loss: 0.0992 - final_out_acc: 0.9394\n",
      "\n",
      "Epoch 00019: final_out_loss improved from 0.10089 to 0.09612, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 20/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.4241 - out11_loss: 0.1121 - out12_loss: 0.1046 - out13_loss: 0.1039 - final_out_loss: 0.1035 - final_out_acc: 0.9344\n",
      "\n",
      "Epoch 00020: final_out_loss did not improve from 0.09612\n",
      "Epoch 21/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.4062 - out11_loss: 0.1064 - out12_loss: 0.1004 - out13_loss: 0.0999 - final_out_loss: 0.0994 - final_out_acc: 0.9377\n",
      "\n",
      "Epoch 00021: final_out_loss did not improve from 0.09612\n",
      "Epoch 22/200\n",
      "62/62 [==============================] - 29s 467ms/step - loss: 0.4453 - out11_loss: 0.1166 - out12_loss: 0.1102 - out13_loss: 0.1092 - final_out_loss: 0.1093 - final_out_acc: 0.9314\n",
      "\n",
      "Epoch 00022: final_out_loss did not improve from 0.09612\n",
      "Epoch 23/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.3746 - out11_loss: 0.0976 - out12_loss: 0.0925 - out13_loss: 0.0924 - final_out_loss: 0.0921 - final_out_acc: 0.9441\n",
      "\n",
      "Epoch 00023: final_out_loss improved from 0.09612 to 0.09165, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 24/200\n",
      "62/62 [==============================] - 30s 477ms/step - loss: 0.4075 - out11_loss: 0.1058 - out12_loss: 0.1013 - out13_loss: 0.1005 - final_out_loss: 0.0999 - final_out_acc: 0.9384\n",
      "\n",
      "Epoch 00024: final_out_loss did not improve from 0.09165\n",
      "Epoch 25/200\n",
      "62/62 [==============================] - 29s 473ms/step - loss: 0.3773 - out11_loss: 0.0989 - out12_loss: 0.0932 - out13_loss: 0.0925 - final_out_loss: 0.0927 - final_out_acc: 0.9421\n",
      "\n",
      "Epoch 00025: final_out_loss improved from 0.09165 to 0.09070, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 26/200\n",
      "62/62 [==============================] - 30s 476ms/step - loss: 0.3771 - out11_loss: 0.0980 - out12_loss: 0.0934 - out13_loss: 0.0928 - final_out_loss: 0.0929 - final_out_acc: 0.9398\n",
      "\n",
      "Epoch 00026: final_out_loss did not improve from 0.09070\n",
      "Epoch 27/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.3317 - out11_loss: 0.0863 - out12_loss: 0.0822 - out13_loss: 0.0816 - final_out_loss: 0.0816 - final_out_acc: 0.9423\n",
      "\n",
      "Epoch 00027: final_out_loss improved from 0.09070 to 0.08340, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 28/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.3376 - out11_loss: 0.0881 - out12_loss: 0.0834 - out13_loss: 0.0831 - final_out_loss: 0.0830 - final_out_acc: 0.9449\n",
      "\n",
      "Epoch 00028: final_out_loss improved from 0.08340 to 0.08308, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 29/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.3595 - out11_loss: 0.0940 - out12_loss: 0.0888 - out13_loss: 0.0884 - final_out_loss: 0.0883 - final_out_acc: 0.9462\n",
      "\n",
      "Epoch 00029: final_out_loss did not improve from 0.08308\n",
      "Epoch 30/200\n",
      "62/62 [==============================] - 30s 483ms/step - loss: 0.3286 - out11_loss: 0.0856 - out12_loss: 0.0812 - out13_loss: 0.0809 - final_out_loss: 0.0808 - final_out_acc: 0.9466\n",
      "\n",
      "Epoch 00030: final_out_loss improved from 0.08308 to 0.08154, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 31/200\n",
      "62/62 [==============================] - 29s 469ms/step - loss: 0.3449 - out11_loss: 0.0889 - out12_loss: 0.0856 - out13_loss: 0.0852 - final_out_loss: 0.0852 - final_out_acc: 0.9439\n",
      "\n",
      "Epoch 00031: final_out_loss did not improve from 0.08154\n",
      "Epoch 32/200\n",
      "62/62 [==============================] - 30s 483ms/step - loss: 0.3524 - out11_loss: 0.0913 - out12_loss: 0.0873 - out13_loss: 0.0869 - final_out_loss: 0.0869 - final_out_acc: 0.9411\n",
      "\n",
      "Epoch 00032: final_out_loss did not improve from 0.08154\n",
      "Epoch 33/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.3396 - out11_loss: 0.0878 - out12_loss: 0.0841 - out13_loss: 0.0838 - final_out_loss: 0.0839 - final_out_acc: 0.9432\n",
      "\n",
      "Epoch 00033: final_out_loss did not improve from 0.08154\n",
      "Epoch 34/200\n",
      "62/62 [==============================] - 30s 481ms/step - loss: 0.3265 - out11_loss: 0.0842 - out12_loss: 0.0810 - out13_loss: 0.0807 - final_out_loss: 0.0806 - final_out_acc: 0.9450\n",
      "\n",
      "Epoch 00034: final_out_loss improved from 0.08154 to 0.08065, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 35/200\n",
      "62/62 [==============================] - 29s 467ms/step - loss: 0.3034 - out11_loss: 0.0786 - out12_loss: 0.0751 - out13_loss: 0.0749 - final_out_loss: 0.0748 - final_out_acc: 0.9472\n",
      "\n",
      "Epoch 00035: final_out_loss improved from 0.08065 to 0.07553, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 36/200\n",
      "62/62 [==============================] - 30s 483ms/step - loss: 0.3285 - out11_loss: 0.0847 - out12_loss: 0.0815 - out13_loss: 0.0811 - final_out_loss: 0.0811 - final_out_acc: 0.9411\n",
      "\n",
      "Epoch 00036: final_out_loss did not improve from 0.07553\n",
      "Epoch 37/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.3214 - out11_loss: 0.0828 - out12_loss: 0.0798 - out13_loss: 0.0794 - final_out_loss: 0.0794 - final_out_acc: 0.9415\n",
      "\n",
      "Epoch 00037: final_out_loss did not improve from 0.07553\n",
      "Epoch 38/200\n",
      "62/62 [==============================] - 30s 483ms/step - loss: 0.3164 - out11_loss: 0.0821 - out12_loss: 0.0783 - out13_loss: 0.0780 - final_out_loss: 0.0780 - final_out_acc: 0.9438\n",
      "\n",
      "Epoch 00038: final_out_loss did not improve from 0.07553\n",
      "Epoch 39/200\n",
      "62/62 [==============================] - 29s 467ms/step - loss: 0.3104 - out11_loss: 0.0802 - out12_loss: 0.0770 - out13_loss: 0.0766 - final_out_loss: 0.0766 - final_out_acc: 0.9452\n",
      "\n",
      "Epoch 00039: final_out_loss did not improve from 0.07553\n",
      "Epoch 40/200\n",
      "62/62 [==============================] - 30s 481ms/step - loss: 0.2758 - out11_loss: 0.0710 - out12_loss: 0.0685 - out13_loss: 0.0681 - final_out_loss: 0.0682 - final_out_acc: 0.9509\n",
      "\n",
      "Epoch 00040: final_out_loss improved from 0.07553 to 0.06652, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 41/200\n",
      "62/62 [==============================] - 28s 448ms/step - loss: 0.3488 - out11_loss: 0.0897 - out12_loss: 0.0863 - out13_loss: 0.0862 - final_out_loss: 0.0865 - final_out_acc: 0.9400\n",
      "\n",
      "Epoch 00041: final_out_loss did not improve from 0.06652\n",
      "Epoch 42/200\n",
      "62/62 [==============================] - 17s 282ms/step - loss: 0.2837 - out11_loss: 0.0736 - out12_loss: 0.0702 - out13_loss: 0.0699 - final_out_loss: 0.0700 - final_out_acc: 0.9484\n",
      "\n",
      "Epoch 00042: final_out_loss did not improve from 0.06652\n",
      "Epoch 43/200\n",
      "62/62 [==============================] - 27s 433ms/step - loss: 0.2997 - out11_loss: 0.0774 - out12_loss: 0.0743 - out13_loss: 0.0740 - final_out_loss: 0.0740 - final_out_acc: 0.9476\n",
      "\n",
      "Epoch 00043: final_out_loss did not improve from 0.06652\n",
      "Epoch 44/200\n",
      "62/62 [==============================] - 23s 375ms/step - loss: 0.3124 - out11_loss: 0.0805 - out12_loss: 0.0776 - out13_loss: 0.0771 - final_out_loss: 0.0772 - final_out_acc: 0.9442\n",
      "\n",
      "Epoch 00044: final_out_loss did not improve from 0.06652\n",
      "Epoch 45/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.3058 - out11_loss: 0.0792 - out12_loss: 0.0757 - out13_loss: 0.0755 - final_out_loss: 0.0754 - final_out_acc: 0.9462\n",
      "\n",
      "Epoch 00045: final_out_loss did not improve from 0.06652\n",
      "Epoch 46/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.2634 - out11_loss: 0.0685 - out12_loss: 0.0652 - out13_loss: 0.0649 - final_out_loss: 0.0648 - final_out_acc: 0.9497\n",
      "\n",
      "Epoch 00046: final_out_loss improved from 0.06652 to 0.06642, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 47/200\n",
      "62/62 [==============================] - 29s 476ms/step - loss: 0.3110 - out11_loss: 0.0808 - out12_loss: 0.0770 - out13_loss: 0.0766 - final_out_loss: 0.0766 - final_out_acc: 0.9392\n",
      "\n",
      "Epoch 00047: final_out_loss did not improve from 0.06642\n",
      "Epoch 48/200\n",
      "62/62 [==============================] - 29s 463ms/step - loss: 0.2734 - out11_loss: 0.0709 - out12_loss: 0.0677 - out13_loss: 0.0674 - final_out_loss: 0.0674 - final_out_acc: 0.9499\n",
      "\n",
      "Epoch 00048: final_out_loss did not improve from 0.06642\n",
      "Epoch 49/200\n",
      "62/62 [==============================] - 29s 473ms/step - loss: 0.2697 - out11_loss: 0.0699 - out12_loss: 0.0668 - out13_loss: 0.0665 - final_out_loss: 0.0665 - final_out_acc: 0.9498\n",
      "\n",
      "Epoch 00049: final_out_loss improved from 0.06642 to 0.06532, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 50/200\n",
      "62/62 [==============================] - 29s 476ms/step - loss: 0.2828 - out11_loss: 0.0732 - out12_loss: 0.0700 - out13_loss: 0.0698 - final_out_loss: 0.0698 - final_out_acc: 0.9481\n",
      "\n",
      "Epoch 00050: final_out_loss did not improve from 0.06532\n",
      "Epoch 51/200\n",
      "62/62 [==============================] - 29s 469ms/step - loss: 0.3098 - out11_loss: 0.0806 - out12_loss: 0.0768 - out13_loss: 0.0762 - final_out_loss: 0.0762 - final_out_acc: 0.9441\n",
      "\n",
      "Epoch 00051: final_out_loss did not improve from 0.06532\n",
      "Epoch 52/200\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.2923 - out11_loss: 0.0759 - out12_loss: 0.0725 - out13_loss: 0.0720 - final_out_loss: 0.0719 - final_out_acc: 0.9464\n",
      "\n",
      "Epoch 00052: final_out_loss did not improve from 0.06532\n",
      "Epoch 53/200\n",
      "62/62 [==============================] - 29s 463ms/step - loss: 0.2648 - out11_loss: 0.0687 - out12_loss: 0.0657 - out13_loss: 0.0652 - final_out_loss: 0.0652 - final_out_acc: 0.9529\n",
      "\n",
      "Epoch 00053: final_out_loss did not improve from 0.06532\n",
      "Epoch 54/200\n",
      "62/62 [==============================] - 30s 485ms/step - loss: 0.2822 - out11_loss: 0.0735 - out12_loss: 0.0699 - out13_loss: 0.0694 - final_out_loss: 0.0694 - final_out_acc: 0.9485\n",
      "\n",
      "Epoch 00054: final_out_loss did not improve from 0.06532\n",
      "Epoch 55/200\n",
      "62/62 [==============================] - 29s 463ms/step - loss: 0.2915 - out11_loss: 0.0751 - out12_loss: 0.0725 - out13_loss: 0.0719 - final_out_loss: 0.0719 - final_out_acc: 0.9442\n",
      "\n",
      "Epoch 00055: final_out_loss did not improve from 0.06532\n",
      "Epoch 56/200\n",
      "62/62 [==============================] - 30s 477ms/step - loss: 0.2944 - out11_loss: 0.0768 - out12_loss: 0.0729 - out13_loss: 0.0724 - final_out_loss: 0.0723 - final_out_acc: 0.9455\n",
      "\n",
      "Epoch 00056: final_out_loss did not improve from 0.06532\n",
      "Epoch 57/200\n",
      "62/62 [==============================] - 28s 457ms/step - loss: 0.2865 - out11_loss: 0.0739 - out12_loss: 0.0711 - out13_loss: 0.0708 - final_out_loss: 0.0707 - final_out_acc: 0.9448\n",
      "\n",
      "Epoch 00057: final_out_loss did not improve from 0.06532\n",
      "Epoch 58/200\n",
      "62/62 [==============================] - 30s 484ms/step - loss: 0.2461 - out11_loss: 0.0637 - out12_loss: 0.0612 - out13_loss: 0.0607 - final_out_loss: 0.0606 - final_out_acc: 0.9551\n",
      "\n",
      "Epoch 00058: final_out_loss improved from 0.06532 to 0.06042, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 59/200\n",
      "62/62 [==============================] - 29s 460ms/step - loss: 0.2695 - out11_loss: 0.0701 - out12_loss: 0.0669 - out13_loss: 0.0663 - final_out_loss: 0.0662 - final_out_acc: 0.9489\n",
      "\n",
      "Epoch 00059: final_out_loss did not improve from 0.06042\n",
      "Epoch 60/200\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.2764 - out11_loss: 0.0715 - out12_loss: 0.0686 - out13_loss: 0.0682 - final_out_loss: 0.0682 - final_out_acc: 0.9488\n",
      "\n",
      "Epoch 00060: final_out_loss did not improve from 0.06042\n",
      "Epoch 61/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.2844 - out11_loss: 0.0720 - out12_loss: 0.0708 - out13_loss: 0.0707 - final_out_loss: 0.0708 - final_out_acc: 0.9475\n",
      "\n",
      "Epoch 00061: final_out_loss did not improve from 0.06042\n",
      "Epoch 62/200\n",
      "62/62 [==============================] - 29s 468ms/step - loss: 0.3025 - out11_loss: 0.0777 - out12_loss: 0.0751 - out13_loss: 0.0748 - final_out_loss: 0.0750 - final_out_acc: 0.9446\n",
      "\n",
      "Epoch 00062: final_out_loss did not improve from 0.06042\n",
      "Epoch 63/200\n",
      "62/62 [==============================] - 30s 479ms/step - loss: 0.2995 - out11_loss: 0.0783 - out12_loss: 0.0742 - out13_loss: 0.0735 - final_out_loss: 0.0735 - final_out_acc: 0.9425\n",
      "\n",
      "Epoch 00063: final_out_loss did not improve from 0.06042\n",
      "Epoch 64/200\n",
      "62/62 [==============================] - 29s 462ms/step - loss: 0.2616 - out11_loss: 0.0679 - out12_loss: 0.0648 - out13_loss: 0.0645 - final_out_loss: 0.0644 - final_out_acc: 0.9486\n",
      "\n",
      "Epoch 00064: final_out_loss did not improve from 0.06042\n",
      "Epoch 65/200\n",
      "62/62 [==============================] - 30s 480ms/step - loss: 0.2888 - out11_loss: 0.0779 - out12_loss: 0.0710 - out13_loss: 0.0700 - final_out_loss: 0.0699 - final_out_acc: 0.9486\n",
      "\n",
      "Epoch 00065: final_out_loss did not improve from 0.06042\n",
      "Epoch 66/200\n",
      "62/62 [==============================] - 29s 464ms/step - loss: 0.2682 - out11_loss: 0.0720 - out12_loss: 0.0659 - out13_loss: 0.0653 - final_out_loss: 0.0651 - final_out_acc: 0.9530\n",
      "\n",
      "Epoch 00066: final_out_loss did not improve from 0.06042\n",
      "Epoch 67/200\n",
      "62/62 [==============================] - 30s 483ms/step - loss: 0.2859 - out11_loss: 0.0752 - out12_loss: 0.0707 - out13_loss: 0.0701 - final_out_loss: 0.0699 - final_out_acc: 0.9436\n",
      "\n",
      "Epoch 00067: final_out_loss did not improve from 0.06042\n",
      "Epoch 68/200\n",
      "62/62 [==============================] - 29s 468ms/step - loss: 0.2534 - out11_loss: 0.0665 - out12_loss: 0.0628 - out13_loss: 0.0621 - final_out_loss: 0.0620 - final_out_acc: 0.9507\n",
      "\n",
      "Epoch 00068: final_out_loss did not improve from 0.06042\n",
      "Epoch 69/200\n",
      "62/62 [==============================] - 30s 484ms/step - loss: 0.2638 - out11_loss: 0.0690 - out12_loss: 0.0653 - out13_loss: 0.0648 - final_out_loss: 0.0646 - final_out_acc: 0.9500\n",
      "\n",
      "Epoch 00069: final_out_loss did not improve from 0.06042\n",
      "Epoch 70/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.2594 - out11_loss: 0.0676 - out12_loss: 0.0644 - out13_loss: 0.0637 - final_out_loss: 0.0637 - final_out_acc: 0.9492\n",
      "\n",
      "Epoch 00070: final_out_loss did not improve from 0.06042\n",
      "Epoch 71/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2605 - out11_loss: 0.0674 - out12_loss: 0.0646 - out13_loss: 0.0643 - final_out_loss: 0.0643 - final_out_acc: 0.9488\n",
      "\n",
      "Epoch 00071: final_out_loss did not improve from 0.06042\n",
      "Epoch 72/200\n",
      "62/62 [==============================] - 29s 472ms/step - loss: 0.2676 - out11_loss: 0.0700 - out12_loss: 0.0663 - out13_loss: 0.0657 - final_out_loss: 0.0656 - final_out_acc: 0.9462\n",
      "\n",
      "Epoch 00072: final_out_loss did not improve from 0.06042\n",
      "Epoch 73/200\n",
      "62/62 [==============================] - 29s 469ms/step - loss: 0.2448 - out11_loss: 0.0640 - out12_loss: 0.0607 - out13_loss: 0.0601 - final_out_loss: 0.0600 - final_out_acc: 0.9516\n",
      "\n",
      "Epoch 00073: final_out_loss improved from 0.06042 to 0.06017, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 74/200\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.2784 - out11_loss: 0.0721 - out12_loss: 0.0691 - out13_loss: 0.0686 - final_out_loss: 0.0686 - final_out_acc: 0.9456\n",
      "\n",
      "Epoch 00074: final_out_loss did not improve from 0.06017\n",
      "Epoch 75/200\n",
      "62/62 [==============================] - 29s 470ms/step - loss: 0.2755 - out11_loss: 0.0710 - out12_loss: 0.0683 - out13_loss: 0.0680 - final_out_loss: 0.0682 - final_out_acc: 0.9495\n",
      "\n",
      "Epoch 00075: final_out_loss did not improve from 0.06017\n",
      "Epoch 76/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2865 - out11_loss: 0.0751 - out12_loss: 0.0709 - out13_loss: 0.0702 - final_out_loss: 0.0702 - final_out_acc: 0.9447\n",
      "\n",
      "Epoch 00076: final_out_loss did not improve from 0.06017\n",
      "Epoch 77/200\n",
      "62/62 [==============================] - 29s 469ms/step - loss: 0.2729 - out11_loss: 0.0713 - out12_loss: 0.0677 - out13_loss: 0.0670 - final_out_loss: 0.0669 - final_out_acc: 0.9494\n",
      "\n",
      "Epoch 00077: final_out_loss did not improve from 0.06017\n",
      "Epoch 78/200\n",
      "62/62 [==============================] - 29s 473ms/step - loss: 0.2770 - out11_loss: 0.0717 - out12_loss: 0.0688 - out13_loss: 0.0683 - final_out_loss: 0.0683 - final_out_acc: 0.9481\n",
      "\n",
      "Epoch 00078: final_out_loss did not improve from 0.06017\n",
      "Epoch 79/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.2875 - out11_loss: 0.0748 - out12_loss: 0.0712 - out13_loss: 0.0708 - final_out_loss: 0.0707 - final_out_acc: 0.9476\n",
      "\n",
      "Epoch 00079: final_out_loss did not improve from 0.06017\n",
      "Epoch 80/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2746 - out11_loss: 0.0708 - out12_loss: 0.0681 - out13_loss: 0.0679 - final_out_loss: 0.0678 - final_out_acc: 0.9500\n",
      "\n",
      "Epoch 00080: final_out_loss did not improve from 0.06017\n",
      "Epoch 81/200\n",
      "62/62 [==============================] - 29s 472ms/step - loss: 0.2475 - out11_loss: 0.0649 - out12_loss: 0.0612 - out13_loss: 0.0608 - final_out_loss: 0.0607 - final_out_acc: 0.9524\n",
      "\n",
      "Epoch 00081: final_out_loss did not improve from 0.06017\n",
      "Epoch 82/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2625 - out11_loss: 0.0680 - out12_loss: 0.0651 - out13_loss: 0.0647 - final_out_loss: 0.0647 - final_out_acc: 0.9512\n",
      "\n",
      "Epoch 00082: final_out_loss did not improve from 0.06017\n",
      "Epoch 83/200\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.2747 - out11_loss: 0.0715 - out12_loss: 0.0682 - out13_loss: 0.0676 - final_out_loss: 0.0674 - final_out_acc: 0.9482\n",
      "\n",
      "Epoch 00083: final_out_loss did not improve from 0.06017\n",
      "Epoch 84/200\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.2630 - out11_loss: 0.0690 - out12_loss: 0.0651 - out13_loss: 0.0645 - final_out_loss: 0.0644 - final_out_acc: 0.9496\n",
      "\n",
      "Epoch 00084: final_out_loss did not improve from 0.06017\n",
      "Epoch 85/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.2448 - out11_loss: 0.0643 - out12_loss: 0.0607 - out13_loss: 0.0600 - final_out_loss: 0.0598 - final_out_acc: 0.9515\n",
      "\n",
      "Epoch 00085: final_out_loss improved from 0.06017 to 0.05997, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 86/200\n",
      "62/62 [==============================] - 30s 481ms/step - loss: 0.2646 - out11_loss: 0.0694 - out12_loss: 0.0655 - out13_loss: 0.0649 - final_out_loss: 0.0648 - final_out_acc: 0.9447\n",
      "\n",
      "Epoch 00086: final_out_loss did not improve from 0.05997\n",
      "Epoch 87/200\n",
      "62/62 [==============================] - 29s 460ms/step - loss: 0.2657 - out11_loss: 0.0693 - out12_loss: 0.0659 - out13_loss: 0.0653 - final_out_loss: 0.0652 - final_out_acc: 0.9456\n",
      "\n",
      "Epoch 00087: final_out_loss did not improve from 0.05997\n",
      "Epoch 88/200\n",
      "62/62 [==============================] - 30s 485ms/step - loss: 0.2815 - out11_loss: 0.0738 - out12_loss: 0.0698 - out13_loss: 0.0690 - final_out_loss: 0.0689 - final_out_acc: 0.9438\n",
      "\n",
      "Epoch 00088: final_out_loss did not improve from 0.05997\n",
      "Epoch 89/200\n",
      "62/62 [==============================] - 29s 461ms/step - loss: 0.2686 - out11_loss: 0.0691 - out12_loss: 0.0668 - out13_loss: 0.0663 - final_out_loss: 0.0664 - final_out_acc: 0.9464\n",
      "\n",
      "Epoch 00089: final_out_loss did not improve from 0.05997\n",
      "Epoch 90/200\n",
      "62/62 [==============================] - 30s 485ms/step - loss: 0.2850 - out11_loss: 0.0745 - out12_loss: 0.0707 - out13_loss: 0.0700 - final_out_loss: 0.0699 - final_out_acc: 0.9408\n",
      "\n",
      "Epoch 00090: final_out_loss did not improve from 0.05997\n",
      "Epoch 91/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.2534 - out11_loss: 0.0660 - out12_loss: 0.0629 - out13_loss: 0.0623 - final_out_loss: 0.0622 - final_out_acc: 0.9502\n",
      "\n",
      "Epoch 00091: final_out_loss did not improve from 0.05997\n",
      "Epoch 92/200\n",
      "62/62 [==============================] - 30s 478ms/step - loss: 0.2445 - out11_loss: 0.0635 - out12_loss: 0.0607 - out13_loss: 0.0602 - final_out_loss: 0.0601 - final_out_acc: 0.9503\n",
      "\n",
      "Epoch 00092: final_out_loss improved from 0.05997 to 0.05970, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 93/200\n",
      "62/62 [==============================] - 29s 468ms/step - loss: 0.2468 - out11_loss: 0.0645 - out12_loss: 0.0612 - out13_loss: 0.0606 - final_out_loss: 0.0605 - final_out_acc: 0.9499\n",
      "\n",
      "Epoch 00093: final_out_loss did not improve from 0.05970\n",
      "Epoch 94/200\n",
      "62/62 [==============================] - 30s 477ms/step - loss: 0.2579 - out11_loss: 0.0677 - out12_loss: 0.0639 - out13_loss: 0.0632 - final_out_loss: 0.0630 - final_out_acc: 0.9499\n",
      "\n",
      "Epoch 00094: final_out_loss did not improve from 0.05970\n",
      "Epoch 95/200\n",
      "62/62 [==============================] - 29s 469ms/step - loss: 0.2409 - out11_loss: 0.0630 - out12_loss: 0.0597 - out13_loss: 0.0591 - final_out_loss: 0.0590 - final_out_acc: 0.9530\n",
      "\n",
      "Epoch 00095: final_out_loss improved from 0.05970 to 0.05880, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 96/200\n",
      "62/62 [==============================] - 29s 473ms/step - loss: 0.2428 - out11_loss: 0.0637 - out12_loss: 0.0602 - out13_loss: 0.0596 - final_out_loss: 0.0593 - final_out_acc: 0.9526\n",
      "\n",
      "Epoch 00096: final_out_loss did not improve from 0.05880\n",
      "Epoch 97/200\n",
      "62/62 [==============================] - 29s 464ms/step - loss: 0.2706 - out11_loss: 0.0709 - out12_loss: 0.0671 - out13_loss: 0.0664 - final_out_loss: 0.0662 - final_out_acc: 0.9469\n",
      "\n",
      "Epoch 00097: final_out_loss did not improve from 0.05880\n",
      "Epoch 98/200\n",
      "62/62 [==============================] - 30s 481ms/step - loss: 0.2519 - out11_loss: 0.0662 - out12_loss: 0.0625 - out13_loss: 0.0617 - final_out_loss: 0.0615 - final_out_acc: 0.9492\n",
      "\n",
      "Epoch 00098: final_out_loss did not improve from 0.05880\n",
      "Epoch 99/200\n",
      "62/62 [==============================] - 29s 467ms/step - loss: 0.2348 - out11_loss: 0.0617 - out12_loss: 0.0582 - out13_loss: 0.0575 - final_out_loss: 0.0574 - final_out_acc: 0.9513\n",
      "\n",
      "Epoch 00099: final_out_loss improved from 0.05880 to 0.05691, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 100/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2813 - out11_loss: 0.0734 - out12_loss: 0.0698 - out13_loss: 0.0691 - final_out_loss: 0.0690 - final_out_acc: 0.9425\n",
      "\n",
      "Epoch 00100: final_out_loss did not improve from 0.05691\n",
      "Epoch 101/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2520 - out11_loss: 0.0651 - out12_loss: 0.0626 - out13_loss: 0.0621 - final_out_loss: 0.0622 - final_out_acc: 0.9486\n",
      "\n",
      "Epoch 00101: final_out_loss did not improve from 0.05691\n",
      "Epoch 102/200\n",
      "62/62 [==============================] - 29s 472ms/step - loss: 0.2557 - out11_loss: 0.0672 - out12_loss: 0.0634 - out13_loss: 0.0626 - final_out_loss: 0.0625 - final_out_acc: 0.9509\n",
      "\n",
      "Epoch 00102: final_out_loss did not improve from 0.05691\n",
      "Epoch 103/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2371 - out11_loss: 0.0622 - out12_loss: 0.0588 - out13_loss: 0.0582 - final_out_loss: 0.0580 - final_out_acc: 0.9517\n",
      "\n",
      "Epoch 00103: final_out_loss did not improve from 0.05691\n",
      "Epoch 104/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.2738 - out11_loss: 0.0712 - out12_loss: 0.0680 - out13_loss: 0.0673 - final_out_loss: 0.0673 - final_out_acc: 0.9446\n",
      "\n",
      "Epoch 00104: final_out_loss did not improve from 0.05691\n",
      "Epoch 105/200\n",
      "62/62 [==============================] - 29s 473ms/step - loss: 0.2811 - out11_loss: 0.0739 - out12_loss: 0.0697 - out13_loss: 0.0688 - final_out_loss: 0.0687 - final_out_acc: 0.9437\n",
      "\n",
      "Epoch 00105: final_out_loss did not improve from 0.05691\n",
      "Epoch 106/200\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.2728 - out11_loss: 0.0712 - out12_loss: 0.0676 - out13_loss: 0.0671 - final_out_loss: 0.0669 - final_out_acc: 0.9437\n",
      "\n",
      "Epoch 00106: final_out_loss did not improve from 0.05691\n",
      "Epoch 107/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2488 - out11_loss: 0.0653 - out12_loss: 0.0617 - out13_loss: 0.0610 - final_out_loss: 0.0608 - final_out_acc: 0.9464\n",
      "\n",
      "Epoch 00107: final_out_loss did not improve from 0.05691\n",
      "Epoch 108/200\n",
      "62/62 [==============================] - 29s 473ms/step - loss: 0.2169 - out11_loss: 0.0572 - out12_loss: 0.0538 - out13_loss: 0.0530 - final_out_loss: 0.0529 - final_out_acc: 0.9547\n",
      "\n",
      "Epoch 00108: final_out_loss improved from 0.05691 to 0.05498, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 109/200\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.2345 - out11_loss: 0.0614 - out12_loss: 0.0582 - out13_loss: 0.0576 - final_out_loss: 0.0573 - final_out_acc: 0.9521\n",
      "\n",
      "Epoch 00109: final_out_loss did not improve from 0.05498\n",
      "Epoch 110/200\n",
      "62/62 [==============================] - 29s 472ms/step - loss: 0.2695 - out11_loss: 0.0706 - out12_loss: 0.0668 - out13_loss: 0.0661 - final_out_loss: 0.0660 - final_out_acc: 0.9458\n",
      "\n",
      "Epoch 00110: final_out_loss did not improve from 0.05498\n",
      "Epoch 111/200\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.2586 - out11_loss: 0.0678 - out12_loss: 0.0643 - out13_loss: 0.0634 - final_out_loss: 0.0632 - final_out_acc: 0.9488\n",
      "\n",
      "Epoch 00111: final_out_loss did not improve from 0.05498\n",
      "Epoch 112/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2436 - out11_loss: 0.0639 - out12_loss: 0.0605 - out13_loss: 0.0597 - final_out_loss: 0.0596 - final_out_acc: 0.9511\n",
      "\n",
      "Epoch 00112: final_out_loss did not improve from 0.05498\n",
      "Epoch 113/200\n",
      "62/62 [==============================] - 29s 472ms/step - loss: 0.2677 - out11_loss: 0.0702 - out12_loss: 0.0664 - out13_loss: 0.0657 - final_out_loss: 0.0654 - final_out_acc: 0.9458\n",
      "\n",
      "Epoch 00113: final_out_loss did not improve from 0.05498\n",
      "Epoch 114/200\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.2431 - out11_loss: 0.0628 - out12_loss: 0.0604 - out13_loss: 0.0599 - final_out_loss: 0.0600 - final_out_acc: 0.9519\n",
      "\n",
      "Epoch 00114: final_out_loss did not improve from 0.05498\n",
      "Epoch 115/200\n",
      "62/62 [==============================] - 29s 462ms/step - loss: 0.2696 - out11_loss: 0.0705 - out12_loss: 0.0670 - out13_loss: 0.0661 - final_out_loss: 0.0660 - final_out_acc: 0.9488\n",
      "\n",
      "Epoch 00115: final_out_loss did not improve from 0.05498\n",
      "Epoch 116/200\n",
      "62/62 [==============================] - 30s 476ms/step - loss: 0.2608 - out11_loss: 0.0682 - out12_loss: 0.0647 - out13_loss: 0.0640 - final_out_loss: 0.0638 - final_out_acc: 0.9488\n",
      "\n",
      "Epoch 00116: final_out_loss did not improve from 0.05498\n",
      "Epoch 117/200\n",
      "62/62 [==============================] - 29s 467ms/step - loss: 0.2439 - out11_loss: 0.0639 - out12_loss: 0.0605 - out13_loss: 0.0598 - final_out_loss: 0.0597 - final_out_acc: 0.9508\n",
      "\n",
      "Epoch 00117: final_out_loss did not improve from 0.05498\n",
      "Epoch 118/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2707 - out11_loss: 0.0710 - out12_loss: 0.0671 - out13_loss: 0.0664 - final_out_loss: 0.0663 - final_out_acc: 0.9474\n",
      "\n",
      "Epoch 00118: final_out_loss did not improve from 0.05498\n",
      "Epoch 119/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.2449 - out11_loss: 0.0638 - out12_loss: 0.0608 - out13_loss: 0.0602 - final_out_loss: 0.0600 - final_out_acc: 0.9516\n",
      "\n",
      "Epoch 00119: final_out_loss did not improve from 0.05498\n",
      "Epoch 120/200\n",
      "62/62 [==============================] - 29s 473ms/step - loss: 0.2345 - out11_loss: 0.0616 - out12_loss: 0.0582 - out13_loss: 0.0575 - final_out_loss: 0.0573 - final_out_acc: 0.9523\n",
      "\n",
      "Epoch 00120: final_out_loss did not improve from 0.05498\n",
      "Epoch 121/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.2816 - out11_loss: 0.0734 - out12_loss: 0.0698 - out13_loss: 0.0693 - final_out_loss: 0.0692 - final_out_acc: 0.9449\n",
      "\n",
      "Epoch 00121: final_out_loss did not improve from 0.05498\n",
      "Epoch 122/200\n",
      "62/62 [==============================] - 29s 467ms/step - loss: 0.2580 - out11_loss: 0.0681 - out12_loss: 0.0640 - out13_loss: 0.0631 - final_out_loss: 0.0628 - final_out_acc: 0.9489\n",
      "\n",
      "Epoch 00122: final_out_loss did not improve from 0.05498\n",
      "Epoch 123/200\n",
      "62/62 [==============================] - 30s 480ms/step - loss: 0.2537 - out11_loss: 0.0666 - out12_loss: 0.0629 - out13_loss: 0.0621 - final_out_loss: 0.0620 - final_out_acc: 0.9498\n",
      "\n",
      "Epoch 00123: final_out_loss did not improve from 0.05498\n",
      "Epoch 124/200\n",
      "62/62 [==============================] - 29s 463ms/step - loss: 0.2448 - out11_loss: 0.0643 - out12_loss: 0.0607 - out13_loss: 0.0600 - final_out_loss: 0.0598 - final_out_acc: 0.9505\n",
      "\n",
      "Epoch 00124: final_out_loss did not improve from 0.05498\n",
      "Epoch 125/200\n",
      "62/62 [==============================] - 30s 480ms/step - loss: 0.2445 - out11_loss: 0.0641 - out12_loss: 0.0607 - out13_loss: 0.0600 - final_out_loss: 0.0598 - final_out_acc: 0.9484\n",
      "\n",
      "Epoch 00125: final_out_loss did not improve from 0.05498\n",
      "Epoch 126/200\n",
      "62/62 [==============================] - 29s 462ms/step - loss: 0.2516 - out11_loss: 0.0659 - out12_loss: 0.0624 - out13_loss: 0.0617 - final_out_loss: 0.0616 - final_out_acc: 0.9487\n",
      "\n",
      "Epoch 00126: final_out_loss did not improve from 0.05498\n",
      "Epoch 127/200\n",
      "62/62 [==============================] - 30s 485ms/step - loss: 0.2492 - out11_loss: 0.0655 - out12_loss: 0.0618 - out13_loss: 0.0611 - final_out_loss: 0.0609 - final_out_acc: 0.9466\n",
      "\n",
      "Epoch 00127: final_out_loss did not improve from 0.05498\n",
      "Epoch 128/200\n",
      "62/62 [==============================] - 29s 461ms/step - loss: 0.2425 - out11_loss: 0.0637 - out12_loss: 0.0602 - out13_loss: 0.0594 - final_out_loss: 0.0592 - final_out_acc: 0.9502\n",
      "\n",
      "Epoch 00128: final_out_loss did not improve from 0.05498\n",
      "Epoch 129/200\n",
      "62/62 [==============================] - 30s 482ms/step - loss: 0.2441 - out11_loss: 0.0644 - out12_loss: 0.0605 - out13_loss: 0.0597 - final_out_loss: 0.0595 - final_out_acc: 0.9477\n",
      "\n",
      "Epoch 00129: final_out_loss did not improve from 0.05498\n",
      "Epoch 130/200\n",
      "62/62 [==============================] - 29s 463ms/step - loss: 0.2524 - out11_loss: 0.0663 - out12_loss: 0.0626 - out13_loss: 0.0618 - final_out_loss: 0.0616 - final_out_acc: 0.9477\n",
      "\n",
      "Epoch 00130: final_out_loss did not improve from 0.05498\n",
      "Epoch 131/200\n",
      "62/62 [==============================] - 30s 482ms/step - loss: 0.2398 - out11_loss: 0.0633 - out12_loss: 0.0595 - out13_loss: 0.0586 - final_out_loss: 0.0584 - final_out_acc: 0.9491\n",
      "\n",
      "Epoch 00131: final_out_loss did not improve from 0.05498\n",
      "Epoch 132/200\n",
      "62/62 [==============================] - 29s 465ms/step - loss: 0.2511 - out11_loss: 0.0658 - out12_loss: 0.0623 - out13_loss: 0.0616 - final_out_loss: 0.0614 - final_out_acc: 0.9476\n",
      "\n",
      "Epoch 00132: final_out_loss did not improve from 0.05498\n",
      "Epoch 133/200\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.2371 - out11_loss: 0.0624 - out12_loss: 0.0588 - out13_loss: 0.0580 - final_out_loss: 0.0579 - final_out_acc: 0.9518\n",
      "\n",
      "Epoch 00133: final_out_loss did not improve from 0.05498\n",
      "Epoch 134/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.2702 - out11_loss: 0.0708 - out12_loss: 0.0670 - out13_loss: 0.0663 - final_out_loss: 0.0661 - final_out_acc: 0.9442\n",
      "\n",
      "Epoch 00134: final_out_loss did not improve from 0.05498\n",
      "Epoch 135/200\n",
      "62/62 [==============================] - 29s 469ms/step - loss: 0.2532 - out11_loss: 0.0664 - out12_loss: 0.0628 - out13_loss: 0.0621 - final_out_loss: 0.0620 - final_out_acc: 0.9491\n",
      "\n",
      "Epoch 00135: final_out_loss did not improve from 0.05498\n",
      "Epoch 136/200\n",
      "62/62 [==============================] - 30s 478ms/step - loss: 0.2471 - out11_loss: 0.0647 - out12_loss: 0.0613 - out13_loss: 0.0606 - final_out_loss: 0.0604 - final_out_acc: 0.9511\n",
      "\n",
      "Epoch 00136: final_out_loss did not improve from 0.05498\n",
      "Epoch 137/200\n",
      "62/62 [==============================] - 29s 461ms/step - loss: 0.2492 - out11_loss: 0.0656 - out12_loss: 0.0618 - out13_loss: 0.0610 - final_out_loss: 0.0608 - final_out_acc: 0.9506\n",
      "\n",
      "Epoch 00137: final_out_loss did not improve from 0.05498\n",
      "Epoch 138/200\n",
      "62/62 [==============================] - 30s 479ms/step - loss: 0.2347 - out11_loss: 0.0616 - out12_loss: 0.0583 - out13_loss: 0.0575 - final_out_loss: 0.0573 - final_out_acc: 0.9491\n",
      "\n",
      "Epoch 00138: final_out_loss did not improve from 0.05498\n",
      "Epoch 139/200\n",
      "62/62 [==============================] - 29s 468ms/step - loss: 0.2492 - out11_loss: 0.0653 - out12_loss: 0.0618 - out13_loss: 0.0611 - final_out_loss: 0.0610 - final_out_acc: 0.9486\n",
      "\n",
      "Epoch 00139: final_out_loss did not improve from 0.05498\n",
      "Epoch 140/200\n",
      "62/62 [==============================] - 29s 476ms/step - loss: 0.2551 - out11_loss: 0.0670 - out12_loss: 0.0633 - out13_loss: 0.0625 - final_out_loss: 0.0623 - final_out_acc: 0.9464\n",
      "\n",
      "Epoch 00140: final_out_loss did not improve from 0.05498\n",
      "Epoch 141/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.2349 - out11_loss: 0.0616 - out12_loss: 0.0582 - out13_loss: 0.0576 - final_out_loss: 0.0575 - final_out_acc: 0.9524\n",
      "\n",
      "Epoch 00141: final_out_loss did not improve from 0.05498\n",
      "Epoch 142/200\n",
      "62/62 [==============================] - 29s 473ms/step - loss: 0.2496 - out11_loss: 0.0659 - out12_loss: 0.0619 - out13_loss: 0.0610 - final_out_loss: 0.0608 - final_out_acc: 0.9496\n",
      "\n",
      "Epoch 00142: final_out_loss did not improve from 0.05498\n",
      "Epoch 143/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2437 - out11_loss: 0.0639 - out12_loss: 0.0605 - out13_loss: 0.0597 - final_out_loss: 0.0595 - final_out_acc: 0.9483\n",
      "\n",
      "Epoch 00143: final_out_loss did not improve from 0.05498\n",
      "Epoch 144/200\n",
      "62/62 [==============================] - 29s 469ms/step - loss: 0.2583 - out11_loss: 0.0672 - out12_loss: 0.0641 - out13_loss: 0.0636 - final_out_loss: 0.0635 - final_out_acc: 0.9492\n",
      "\n",
      "Epoch 00144: final_out_loss did not improve from 0.05498\n",
      "Epoch 145/200\n",
      "62/62 [==============================] - 30s 478ms/step - loss: 0.2858 - out11_loss: 0.0752 - out12_loss: 0.0709 - out13_loss: 0.0700 - final_out_loss: 0.0697 - final_out_acc: 0.9422\n",
      "\n",
      "Epoch 00145: final_out_loss did not improve from 0.05498\n",
      "Epoch 146/200\n",
      "62/62 [==============================] - 29s 465ms/step - loss: 0.2539 - out11_loss: 0.0669 - out12_loss: 0.0630 - out13_loss: 0.0621 - final_out_loss: 0.0619 - final_out_acc: 0.9468\n",
      "\n",
      "Epoch 00146: final_out_loss did not improve from 0.05498\n",
      "Epoch 147/200\n",
      "62/62 [==============================] - 30s 478ms/step - loss: 0.2374 - out11_loss: 0.0623 - out12_loss: 0.0588 - out13_loss: 0.0581 - final_out_loss: 0.0580 - final_out_acc: 0.9521\n",
      "\n",
      "Epoch 00147: final_out_loss did not improve from 0.05498\n",
      "Epoch 148/200\n",
      "62/62 [==============================] - 29s 467ms/step - loss: 0.2499 - out11_loss: 0.0659 - out12_loss: 0.0620 - out13_loss: 0.0611 - final_out_loss: 0.0609 - final_out_acc: 0.9474\n",
      "\n",
      "Epoch 00148: final_out_loss did not improve from 0.05498\n",
      "Epoch 149/200\n",
      "62/62 [==============================] - 30s 480ms/step - loss: 0.2577 - out11_loss: 0.0678 - out12_loss: 0.0640 - out13_loss: 0.0630 - final_out_loss: 0.0628 - final_out_acc: 0.9451\n",
      "\n",
      "Epoch 00149: final_out_loss did not improve from 0.05498\n",
      "Epoch 150/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.2514 - out11_loss: 0.0661 - out12_loss: 0.0623 - out13_loss: 0.0616 - final_out_loss: 0.0614 - final_out_acc: 0.9453\n",
      "\n",
      "Epoch 00150: final_out_loss did not improve from 0.05498\n",
      "Epoch 151/200\n",
      "62/62 [==============================] - 30s 478ms/step - loss: 0.2303 - out11_loss: 0.0601 - out12_loss: 0.0571 - out13_loss: 0.0566 - final_out_loss: 0.0564 - final_out_acc: 0.9545\n",
      "\n",
      "Epoch 00151: final_out_loss did not improve from 0.05498\n",
      "Epoch 152/200\n",
      "62/62 [==============================] - 29s 464ms/step - loss: 0.2520 - out11_loss: 0.0655 - out12_loss: 0.0627 - out13_loss: 0.0620 - final_out_loss: 0.0619 - final_out_acc: 0.9524\n",
      "\n",
      "Epoch 00152: final_out_loss did not improve from 0.05498\n",
      "Epoch 153/200\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.2491 - out11_loss: 0.0655 - out12_loss: 0.0615 - out13_loss: 0.0610 - final_out_loss: 0.0611 - final_out_acc: 0.9499\n",
      "\n",
      "Epoch 00153: final_out_loss did not improve from 0.05498\n",
      "Epoch 154/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.2494 - out11_loss: 0.0656 - out12_loss: 0.0619 - out13_loss: 0.0611 - final_out_loss: 0.0609 - final_out_acc: 0.9483\n",
      "\n",
      "Epoch 00154: final_out_loss did not improve from 0.05498\n",
      "Epoch 155/200\n",
      "62/62 [==============================] - 29s 473ms/step - loss: 0.2621 - out11_loss: 0.0691 - out12_loss: 0.0651 - out13_loss: 0.0641 - final_out_loss: 0.0639 - final_out_acc: 0.9456\n",
      "\n",
      "Epoch 00155: final_out_loss did not improve from 0.05498\n",
      "Epoch 156/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2393 - out11_loss: 0.0628 - out12_loss: 0.0594 - out13_loss: 0.0587 - final_out_loss: 0.0585 - final_out_acc: 0.9508\n",
      "\n",
      "Epoch 00156: final_out_loss did not improve from 0.05498\n",
      "Epoch 157/200\n",
      "62/62 [==============================] - 29s 469ms/step - loss: 0.2179 - out11_loss: 0.0575 - out12_loss: 0.0540 - out13_loss: 0.0533 - final_out_loss: 0.0531 - final_out_acc: 0.9544\n",
      "\n",
      "Epoch 00157: final_out_loss improved from 0.05498 to 0.05414, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 158/200\n",
      "62/62 [==============================] - 30s 479ms/step - loss: 0.2415 - out11_loss: 0.0628 - out12_loss: 0.0600 - out13_loss: 0.0594 - final_out_loss: 0.0593 - final_out_acc: 0.9506\n",
      "\n",
      "Epoch 00158: final_out_loss did not improve from 0.05414\n",
      "Epoch 159/200\n",
      "62/62 [==============================] - 28s 459ms/step - loss: 0.2290 - out11_loss: 0.0604 - out12_loss: 0.0567 - out13_loss: 0.0560 - final_out_loss: 0.0558 - final_out_acc: 0.9532\n",
      "\n",
      "Epoch 00159: final_out_loss did not improve from 0.05414\n",
      "Epoch 160/200\n",
      "62/62 [==============================] - 30s 484ms/step - loss: 0.2511 - out11_loss: 0.0667 - out12_loss: 0.0622 - out13_loss: 0.0612 - final_out_loss: 0.0610 - final_out_acc: 0.9477\n",
      "\n",
      "Epoch 00160: final_out_loss did not improve from 0.05414\n",
      "Epoch 161/200\n",
      "62/62 [==============================] - 29s 463ms/step - loss: 0.2314 - out11_loss: 0.0610 - out12_loss: 0.0573 - out13_loss: 0.0566 - final_out_loss: 0.0565 - final_out_acc: 0.9529\n",
      "\n",
      "Epoch 00161: final_out_loss did not improve from 0.05414\n",
      "Epoch 162/200\n",
      "62/62 [==============================] - 30s 484ms/step - loss: 0.2388 - out11_loss: 0.0628 - out12_loss: 0.0592 - out13_loss: 0.0585 - final_out_loss: 0.0583 - final_out_acc: 0.9509\n",
      "\n",
      "Epoch 00162: final_out_loss did not improve from 0.05414\n",
      "Epoch 163/200\n",
      "62/62 [==============================] - 29s 462ms/step - loss: 0.2147 - out11_loss: 0.0565 - out12_loss: 0.0532 - out13_loss: 0.0526 - final_out_loss: 0.0524 - final_out_acc: 0.9566\n",
      "\n",
      "Epoch 00163: final_out_loss improved from 0.05414 to 0.05278, saving model to trained_model/CHASEDB1/Final_Emer_Iteration_3_cropsize_128_epochs_200.hdf5\n",
      "Epoch 164/200\n",
      "62/62 [==============================] - 30s 482ms/step - loss: 0.2221 - out11_loss: 0.0588 - out12_loss: 0.0550 - out13_loss: 0.0542 - final_out_loss: 0.0540 - final_out_acc: 0.9527\n",
      "\n",
      "Epoch 00164: final_out_loss did not improve from 0.05278\n",
      "Epoch 165/200\n",
      "62/62 [==============================] - 29s 463ms/step - loss: 0.2267 - out11_loss: 0.0595 - out12_loss: 0.0562 - out13_loss: 0.0556 - final_out_loss: 0.0554 - final_out_acc: 0.9510\n",
      "\n",
      "Epoch 00165: final_out_loss did not improve from 0.05278\n",
      "Epoch 166/200\n",
      "62/62 [==============================] - 29s 476ms/step - loss: 0.2374 - out11_loss: 0.0625 - out12_loss: 0.0589 - out13_loss: 0.0582 - final_out_loss: 0.0579 - final_out_acc: 0.9515\n",
      "\n",
      "Epoch 00166: final_out_loss did not improve from 0.05278\n",
      "Epoch 167/200\n",
      "62/62 [==============================] - 29s 470ms/step - loss: 0.2344 - out11_loss: 0.0619 - out12_loss: 0.0581 - out13_loss: 0.0573 - final_out_loss: 0.0571 - final_out_acc: 0.9519\n",
      "\n",
      "Epoch 00167: final_out_loss did not improve from 0.05278\n",
      "Epoch 168/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.2326 - out11_loss: 0.0608 - out12_loss: 0.0577 - out13_loss: 0.0571 - final_out_loss: 0.0570 - final_out_acc: 0.9525\n",
      "\n",
      "Epoch 00168: final_out_loss did not improve from 0.05278\n",
      "Epoch 169/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2367 - out11_loss: 0.0624 - out12_loss: 0.0587 - out13_loss: 0.0580 - final_out_loss: 0.0577 - final_out_acc: 0.9522\n",
      "\n",
      "Epoch 00169: final_out_loss did not improve from 0.05278\n",
      "Epoch 170/200\n",
      "62/62 [==============================] - 29s 465ms/step - loss: 0.2562 - out11_loss: 0.0677 - out12_loss: 0.0635 - out13_loss: 0.0626 - final_out_loss: 0.0624 - final_out_acc: 0.9462\n",
      "\n",
      "Epoch 00170: final_out_loss did not improve from 0.05278\n",
      "Epoch 171/200\n",
      "62/62 [==============================] - 30s 483ms/step - loss: 0.2488 - out11_loss: 0.0650 - out12_loss: 0.0617 - out13_loss: 0.0611 - final_out_loss: 0.0610 - final_out_acc: 0.9493\n",
      "\n",
      "Epoch 00171: final_out_loss did not improve from 0.05278\n",
      "Epoch 172/200\n",
      "62/62 [==============================] - 29s 462ms/step - loss: 0.2189 - out11_loss: 0.0575 - out12_loss: 0.0543 - out13_loss: 0.0536 - final_out_loss: 0.0535 - final_out_acc: 0.9574\n",
      "\n",
      "Epoch 00172: final_out_loss did not improve from 0.05278\n",
      "Epoch 173/200\n",
      "62/62 [==============================] - 30s 477ms/step - loss: 0.2512 - out11_loss: 0.0664 - out12_loss: 0.0623 - out13_loss: 0.0614 - final_out_loss: 0.0612 - final_out_acc: 0.9467\n",
      "\n",
      "Epoch 00173: final_out_loss did not improve from 0.05278\n",
      "Epoch 174/200\n",
      "62/62 [==============================] - 29s 465ms/step - loss: 0.2194 - out11_loss: 0.0578 - out12_loss: 0.0544 - out13_loss: 0.0537 - final_out_loss: 0.0535 - final_out_acc: 0.9541\n",
      "\n",
      "Epoch 00174: final_out_loss did not improve from 0.05278\n",
      "Epoch 175/200\n",
      "62/62 [==============================] - 30s 480ms/step - loss: 0.2340 - out11_loss: 0.0617 - out12_loss: 0.0580 - out13_loss: 0.0572 - final_out_loss: 0.0570 - final_out_acc: 0.9529\n",
      "\n",
      "Epoch 00175: final_out_loss did not improve from 0.05278\n",
      "Epoch 176/200\n",
      "62/62 [==============================] - 29s 464ms/step - loss: 0.2337 - out11_loss: 0.0616 - out12_loss: 0.0579 - out13_loss: 0.0572 - final_out_loss: 0.0570 - final_out_acc: 0.9536\n",
      "\n",
      "Epoch 00176: final_out_loss did not improve from 0.05278\n",
      "Epoch 177/200\n",
      "62/62 [==============================] - 29s 471ms/step - loss: 0.2547 - out11_loss: 0.0675 - out12_loss: 0.0632 - out13_loss: 0.0621 - final_out_loss: 0.0619 - final_out_acc: 0.9460\n",
      "\n",
      "Epoch 00177: final_out_loss did not improve from 0.05278\n",
      "Epoch 178/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2492 - out11_loss: 0.0663 - out12_loss: 0.0618 - out13_loss: 0.0607 - final_out_loss: 0.0604 - final_out_acc: 0.9477\n",
      "\n",
      "Epoch 00178: final_out_loss did not improve from 0.05278\n",
      "Epoch 179/200\n",
      "62/62 [==============================] - 29s 467ms/step - loss: 0.2378 - out11_loss: 0.0623 - out12_loss: 0.0589 - out13_loss: 0.0584 - final_out_loss: 0.0582 - final_out_acc: 0.9490\n",
      "\n",
      "Epoch 00179: final_out_loss did not improve from 0.05278\n",
      "Epoch 180/200\n",
      "62/62 [==============================] - 30s 476ms/step - loss: 0.2741 - out11_loss: 0.0723 - out12_loss: 0.0680 - out13_loss: 0.0671 - final_out_loss: 0.0667 - final_out_acc: 0.9402\n",
      "\n",
      "Epoch 00180: final_out_loss did not improve from 0.05278\n",
      "Epoch 181/200\n",
      "62/62 [==============================] - 29s 468ms/step - loss: 0.2328 - out11_loss: 0.0614 - out12_loss: 0.0578 - out13_loss: 0.0569 - final_out_loss: 0.0567 - final_out_acc: 0.9524\n",
      "\n",
      "Epoch 00181: final_out_loss did not improve from 0.05278\n",
      "Epoch 182/200\n",
      "62/62 [==============================] - 30s 478ms/step - loss: 0.2775 - out11_loss: 0.0729 - out12_loss: 0.0688 - out13_loss: 0.0680 - final_out_loss: 0.0678 - final_out_acc: 0.9426\n",
      "\n",
      "Epoch 00182: final_out_loss did not improve from 0.05278\n",
      "Epoch 183/200\n",
      "62/62 [==============================] - 29s 463ms/step - loss: 0.2313 - out11_loss: 0.0612 - out12_loss: 0.0573 - out13_loss: 0.0565 - final_out_loss: 0.0563 - final_out_acc: 0.9528\n",
      "\n",
      "Epoch 00183: final_out_loss did not improve from 0.05278\n",
      "Epoch 184/200\n",
      "62/62 [==============================] - 30s 481ms/step - loss: 0.2416 - out11_loss: 0.0634 - out12_loss: 0.0600 - out13_loss: 0.0591 - final_out_loss: 0.0591 - final_out_acc: 0.9506\n",
      "\n",
      "Epoch 00184: final_out_loss did not improve from 0.05278\n",
      "Epoch 185/200\n",
      "62/62 [==============================] - 29s 463ms/step - loss: 0.2453 - out11_loss: 0.0649 - out12_loss: 0.0609 - out13_loss: 0.0599 - final_out_loss: 0.0596 - final_out_acc: 0.9507\n",
      "\n",
      "Epoch 00185: final_out_loss did not improve from 0.05278\n",
      "Epoch 186/200\n",
      "62/62 [==============================] - 30s 480ms/step - loss: 0.2380 - out11_loss: 0.0629 - out12_loss: 0.0590 - out13_loss: 0.0582 - final_out_loss: 0.0579 - final_out_acc: 0.9503\n",
      "\n",
      "Epoch 00186: final_out_loss did not improve from 0.05278\n",
      "Epoch 187/200\n",
      "62/62 [==============================] - 29s 469ms/step - loss: 0.2325 - out11_loss: 0.0613 - out12_loss: 0.0577 - out13_loss: 0.0569 - final_out_loss: 0.0566 - final_out_acc: 0.9507\n",
      "\n",
      "Epoch 00187: final_out_loss did not improve from 0.05278\n",
      "Epoch 188/200\n",
      "62/62 [==============================] - 29s 468ms/step - loss: 0.2370 - out11_loss: 0.0621 - out12_loss: 0.0589 - out13_loss: 0.0581 - final_out_loss: 0.0579 - final_out_acc: 0.9514\n",
      "\n",
      "Epoch 00188: final_out_loss did not improve from 0.05278\n",
      "Epoch 189/200\n",
      "62/62 [==============================] - 30s 477ms/step - loss: 0.2285 - out11_loss: 0.0601 - out12_loss: 0.0567 - out13_loss: 0.0560 - final_out_loss: 0.0558 - final_out_acc: 0.9510\n",
      "\n",
      "Epoch 00189: final_out_loss did not improve from 0.05278\n",
      "Epoch 190/200\n",
      "62/62 [==============================] - 29s 466ms/step - loss: 0.2325 - out11_loss: 0.0612 - out12_loss: 0.0577 - out13_loss: 0.0569 - final_out_loss: 0.0567 - final_out_acc: 0.9520\n",
      "\n",
      "Epoch 00190: final_out_loss did not improve from 0.05278\n",
      "Epoch 191/200\n",
      "62/62 [==============================] - 30s 482ms/step - loss: 0.2480 - out11_loss: 0.0654 - out12_loss: 0.0616 - out13_loss: 0.0607 - final_out_loss: 0.0604 - final_out_acc: 0.9474\n",
      "\n",
      "Epoch 00191: final_out_loss did not improve from 0.05278\n",
      "Epoch 192/200\n",
      "62/62 [==============================] - 29s 461ms/step - loss: 0.2266 - out11_loss: 0.0600 - out12_loss: 0.0562 - out13_loss: 0.0553 - final_out_loss: 0.0551 - final_out_acc: 0.9531\n",
      "\n",
      "Epoch 00192: final_out_loss did not improve from 0.05278\n",
      "Epoch 193/200\n",
      "62/62 [==============================] - 30s 481ms/step - loss: 0.2433 - out11_loss: 0.0642 - out12_loss: 0.0604 - out13_loss: 0.0595 - final_out_loss: 0.0593 - final_out_acc: 0.9495\n",
      "\n",
      "Epoch 00193: final_out_loss did not improve from 0.05278\n",
      "Epoch 194/200\n",
      "62/62 [==============================] - 29s 460ms/step - loss: 0.2454 - out11_loss: 0.0643 - out12_loss: 0.0609 - out13_loss: 0.0602 - final_out_loss: 0.0601 - final_out_acc: 0.9519\n",
      "\n",
      "Epoch 00194: final_out_loss did not improve from 0.05278\n",
      "Epoch 195/200\n",
      "62/62 [==============================] - 30s 484ms/step - loss: 0.2752 - out11_loss: 0.0724 - out12_loss: 0.0682 - out13_loss: 0.0674 - final_out_loss: 0.0672 - final_out_acc: 0.9424\n",
      "\n",
      "Epoch 00195: final_out_loss did not improve from 0.05278\n",
      "Epoch 196/200\n",
      "62/62 [==============================] - 29s 464ms/step - loss: 0.2428 - out11_loss: 0.0639 - out12_loss: 0.0602 - out13_loss: 0.0595 - final_out_loss: 0.0593 - final_out_acc: 0.9488\n",
      "\n",
      "Epoch 00196: final_out_loss did not improve from 0.05278\n",
      "Epoch 197/200\n",
      "62/62 [==============================] - 29s 473ms/step - loss: 0.2579 - out11_loss: 0.0680 - out12_loss: 0.0639 - out13_loss: 0.0631 - final_out_loss: 0.0629 - final_out_acc: 0.9437\n",
      "\n",
      "Epoch 00197: final_out_loss did not improve from 0.05278\n",
      "Epoch 198/200\n",
      "62/62 [==============================] - 29s 474ms/step - loss: 0.2394 - out11_loss: 0.0635 - out12_loss: 0.0594 - out13_loss: 0.0584 - final_out_loss: 0.0582 - final_out_acc: 0.9481\n",
      "\n",
      "Epoch 00198: final_out_loss did not improve from 0.05278\n",
      "Epoch 199/200\n",
      "62/62 [==============================] - 29s 470ms/step - loss: 0.2217 - out11_loss: 0.0585 - out12_loss: 0.0549 - out13_loss: 0.0542 - final_out_loss: 0.0540 - final_out_acc: 0.9529\n",
      "\n",
      "Epoch 00199: final_out_loss did not improve from 0.05278\n",
      "Epoch 200/200\n",
      "62/62 [==============================] - 30s 482ms/step - loss: 0.2659 - out11_loss: 0.0693 - out12_loss: 0.0662 - out13_loss: 0.0653 - final_out_loss: 0.0651 - final_out_acc: 0.9451\n",
      "\n",
      "Epoch 00200: final_out_loss did not improve from 0.05278\n"
     ]
    }
   ],
   "source": [
    "############Training\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend import tensorflow_backend\n",
    "import os\n",
    "from train import train\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "session = tf.Session(config=config)\n",
    "tensorflow_backend.set_session(session)\n",
    "\n",
    "\n",
    "#epochs>100 will be enough, but slower\n",
    "#Training may be unstable due to random initialization,\n",
    "#Try it again if out2_auc doesn't increase.\n",
    "train(iteration=3, DATASET='CHASEDB1', # DRIVE, CHASEDB1 or STARE\n",
    "       batch_size=32, epochs=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/li/anaconda3/envs/univ/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/li/anaconda3/envs/univ/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model : Final_Emer_Iteration_3_cropsize_128_epochs_200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [38:21<00:00, 253.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " out4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under the ROC curve: 0.9850708004868491\n",
      "\n",
      "Area under Precision-Recall curve: 0.8949708967746102\n",
      "\n",
      "Confusion matrix:  Costum threshold (for positive) of 0.5\n",
      "[[4762602   85809]\n",
      " [  98043  384995]]\n",
      "Global Accuracy: 0.9655155662184896\n",
      "Specificity: 0.9823016241816133\n",
      "Sensitivity: 0.7970283911410696\n",
      "Precision: 0.8177394414660878\n",
      "\n",
      "Jaccard similarity score: 0.9655155662184896\n"
     ]
    }
   ],
   "source": [
    "############Test\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend import tensorflow_backend\n",
    "import os\n",
    "from predict import predict\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "session = tf.Session(config=config)\n",
    "tensorflow_backend.set_session(session)\n",
    "\n",
    "\n",
    "#stride_size = 3 will be better, but slower\n",
    "predict(batch_size=32, epochs=200, iteration=3, stride_size=3, DATASET='CHASEDB1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
